{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94086f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from glob import glob\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import grad\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import UnidentifiedImageError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee66d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 17 13:46:26 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   47C    P8              3W /  140W |    1365MiB /   8188MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      8612    C+G   ...ekyb3d8bbwe\\Microsoft.CmdPal.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     14024    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "|    0   N/A  N/A     17888    C+G   ...\\PowerToys\\PowerToys.FancyZones.exe      N/A      |\n",
      "|    0   N/A  N/A     23336    C+G   C:\\Windows\\System32\\NahimicSvc64.exe        N/A      |\n",
      "|    0   N/A  N/A     29184    C+G   ...pps\\Work\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     30564    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     32720    C+G   ...on\\137.0.3296.83\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     36756    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     37696    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     44268    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     44664    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     45464    C+G   ...werToys\\PowerToys.ColorPickerUI.exe      N/A      |\n",
      "|    0   N/A  N/A     48100    C+G   ...1.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A     51868    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     52180    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     52980    C+G   ...m\\radeonsoftware\\RadeonSoftware.exe      N/A      |\n",
      "|    0   N/A  N/A     53756    C+G   ...werToys\\PowerToys.PowerLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A     56612    C+G   ...ys\\WinUI3Apps\\PowerToys.Peek.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     57192    C+G   ...nr4m\\radeonsoftware\\AMDRSSrcExt.exe      N/A      |\n",
      "|    0   N/A  N/A     58576    C+G   C:\\Apps\\Work\\ZenBrowser\\zen.exe             N/A      |\n",
      "|    0   N/A  N/A     59560    C+G   C:\\Apps\\Work\\ZenBrowser\\zen.exe             N/A      |\n",
      "|    0   N/A  N/A     60828    C+G   ...s\\System32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A     60848    C+G   ...5.0_x64__w2gh52qy24etm\\Nahimic3.exe      N/A      |\n",
      "|    0   N/A  N/A     63712    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4c4d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should print True\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "683e3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_size = 128\n",
    "z_dim = 128\n",
    "batch_size = 64\n",
    "lambda_gp = 10\n",
    "num_epochs = 100\n",
    "lr = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f9fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee495404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset_path = \"C:/College/Projects/X-RayComparison/Data/train\"  # Update this to the correct path\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2c41442",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=128, img_channels=1, features_g=64):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, features_g * 16, 4, 1, 0),  # 4x4\n",
    "            nn.BatchNorm2d(features_g * 16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g * 16, features_g * 8, 4, 2, 1),  # 8x8\n",
    "            nn.BatchNorm2d(features_g * 8),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g * 8, features_g * 4, 4, 2, 1),  # 16x16\n",
    "            nn.BatchNorm2d(features_g * 4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g * 4, features_g * 2, 4, 2, 1),  # 32x32\n",
    "            nn.BatchNorm2d(features_g * 2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g * 2, features_g, 4, 2, 1),  # 64x64\n",
    "            nn.BatchNorm2d(features_g),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g, img_channels, 4, 2, 1),  # 128x128\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22810489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Penalty\n",
    "def gradient_penalty(critic, real, fake):\n",
    "    batch_size, C, H, W = real.shape\n",
    "    epsilon = torch.rand(batch_size, 1, 1, 1, device=device).expand_as(real)\n",
    "    interpolated = (epsilon * real + (1 - epsilon) * fake).requires_grad_(True)\n",
    "\n",
    "    mixed_scores = critic(interpolated)\n",
    "    gradient = grad(\n",
    "        outputs=mixed_scores,\n",
    "        inputs=interpolated,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(batch_size, -1)\n",
    "    gp = ((gradient.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e5c76ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Critic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize\u001b[39;00m\n\u001b[0;32m      2\u001b[0m gen \u001b[38;5;241m=\u001b[39m Generator(z_dim\u001b[38;5;241m=\u001b[39mz_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 3\u001b[0m critic \u001b[38;5;241m=\u001b[39m \u001b[43mDiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      5\u001b[0m opt_gen \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(gen\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.9\u001b[39m))\n\u001b[0;32m      6\u001b[0m opt_critic \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(critic\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.9\u001b[39m))\n",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m, in \u001b[0;36mDiscriminator.__init__\u001b[1;34m(self, img_channels, feature_d)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, feature_d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28msuper\u001b[39m(\u001b[43mCritic\u001b[49m, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;66;03m# Input: N x 1 x 128 x 128\u001b[39;00m\n\u001b[0;32m      6\u001b[0m         nn\u001b[38;5;241m.\u001b[39mConv2d(img_channels, feature_d, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m),  \u001b[38;5;66;03m# 64x64\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m         nn\u001b[38;5;241m.\u001b[39mConv2d(feature_d \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m),  \u001b[38;5;66;03m# 1x1\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Critic' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "gen = Generator(z_dim=z_dim).to(device)\n",
    "critic = Discriminator().to(device)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.0, 0.9))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=lr, betas=(0.0, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f26cd209",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_d=64):\n",
    "        super(Critic, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # Input: N x 1 x 128 x 128\n",
    "            nn.Conv2d(img_channels, feature_d, 4, 2, 1),  # 64x64\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(feature_d, feature_d * 2, 4, 2, 1),  # 32x32\n",
    "            nn.BatchNorm2d(feature_d * 2), # Corrected: should be feature_d * 2\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(feature_d * 2, feature_d * 4, 4, 2, 1),  # 16x16\n",
    "            nn.BatchNorm2d(feature_d * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(feature_d * 4, feature_d * 8, 4, 2, 1),  # 8x8\n",
    "            nn.BatchNorm2d(feature_d * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(feature_d * 8, feature_d * 16, 4, 2, 1),  # 4x4\n",
    "            nn.BatchNorm2d(feature_d * 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(feature_d * 16, 1, 4, 1, 0),  # 1x1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0b2449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeImageFolder(ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        try:\n",
    "            sample = self.loader(path)\n",
    "        except UnidentifiedImageError:\n",
    "            # Replace with a black image or skip with random image\n",
    "            sample = Image.new(\"L\", (128, 128))  # Grayscale fallback\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f17882ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake, device):\n",
    "    batch_size, c, h, w = real.shape\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1, device=device).expand_as(real)\n",
    "\n",
    "    interpolated = (alpha * real + (1 - alpha) * fake).requires_grad_(True)\n",
    "\n",
    "    critic_interpolated = critic(interpolated)\n",
    "    grad_outputs = torch.ones_like(critic_interpolated, device=device)\n",
    "\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=critic_interpolated,\n",
    "        inputs=interpolated,\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    grad_norm = gradients.norm(2, dim=1)\n",
    "    gp = ((grad_norm - 1) ** 2).mean()\n",
    "    return gp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f310b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"generated_samples\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c4ee54c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/576 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given normalized_shape=[128, 64, 64], expected input with shape [*, 128, 64, 64], but got input of size[64, 128, 32, 32]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(cur_batch_size, z_dim, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     15\u001b[0m fake \u001b[38;5;241m=\u001b[39m gen(noise)\n\u001b[1;32m---> 17\u001b[0m critic_real \u001b[38;5;241m=\u001b[39m \u001b[43mcritic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     18\u001b[0m critic_fake \u001b[38;5;241m=\u001b[39m critic(fake\u001b[38;5;241m.\u001b[39mdetach())\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m gp \u001b[38;5;241m=\u001b[39m gradient_penalty(critic, real, fake, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[19], line 22\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\normalization.py:217\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\functional.py:2900\u001b[0m, in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m   2891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2892\u001b[0m         layer_norm,\n\u001b[0;32m   2893\u001b[0m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2898\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m   2899\u001b[0m     )\n\u001b[1;32m-> 2900\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2901\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2902\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given normalized_shape=[128, 64, 64], expected input with shape [*, 128, 64, 64], but got input of size[64, 128, 32, 32]"
     ]
    }
   ],
   "source": [
    "\n",
    "critic_iterations = 5  # Number of Critic updates per Generator update\n",
    "step = 0\n",
    "fixed_noise = torch.randn(64, z_dim, 1, 1).to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "    \n",
    "    for batch_idx, (real, _) in enumerate(loop):\n",
    "        real = real.to(device)\n",
    "        cur_batch_size = real.size(0)\n",
    "\n",
    "        # === Train Critic ===\n",
    "        for _ in range(critic_iterations):\n",
    "            noise = torch.randn(cur_batch_size, z_dim, 1, 1, device=device)\n",
    "            fake = gen(noise)\n",
    "\n",
    "            critic_real = critic(real).view(-1)\n",
    "            critic_fake = critic(fake.detach()).view(-1)\n",
    "\n",
    "            gp = gradient_penalty(critic, real, fake, device=device)\n",
    "            loss_critic = -torch.mean(critic_real) + torch.mean(critic_fake) + lambda_gp * gp\n",
    "\n",
    "            opt_critic.zero_grad()\n",
    "            loss_critic.backward()\n",
    "            opt_critic.step()\n",
    "\n",
    "        # === Train Generator ===\n",
    "        noise = torch.randn(cur_batch_size, z_dim, 1, 1, device=device)\n",
    "        fake = gen(noise)\n",
    "        output = critic(fake).view(-1)\n",
    "        loss_gen = -torch.mean(output)\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # === Logging ===\n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        loop.set_postfix(critic_loss=loss_critic.item(), gen_loss=loss_gen.item())\n",
    "\n",
    "        # === Save Sample Images ===\n",
    "        if step % 500 == 0:\n",
    "            with torch.no_grad():\n",
    "                fake_samples = gen(fixed_noise)\n",
    "                utils.save_image(fake_samples, f\"generated_samples/sample_{step}.png\", normalize=True, nrow=8)\n",
    "        step += 1\n",
    "\n",
    "    # === Save Model Checkpoints ===\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(gen.state_dict(), f\"checkpoints/gen_epoch_{epoch+1}.pth\")\n",
    "        torch.save(critic.state_dict(), f\"checkpoints/critic_epoch_{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3890a92",
   "metadata": {},
   "source": [
    "## The cells below are working finally ðŸ˜­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24722dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:49<00:00,  1.65it/s, critic_loss=-19.6, gen_loss=68.2]\n",
      "Epoch [2/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:52<00:00,  1.64it/s, critic_loss=-15.7, gen_loss=123] \n",
      "Epoch [3/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:52<00:00,  1.63it/s, critic_loss=-12.6, gen_loss=121] \n",
      "Epoch [4/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:51<00:00,  1.64it/s, critic_loss=-8.92, gen_loss=107] \n",
      "Epoch [5/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:51<00:00,  1.64it/s, critic_loss=-14.7, gen_loss=137] \n",
      "Epoch [6/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:51<00:00,  1.64it/s, critic_loss=-20.9, gen_loss=100] \n",
      "Epoch [7/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:51<00:00,  1.64it/s, critic_loss=-11, gen_loss=113]   \n",
      "Epoch [8/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:51<00:00,  1.64it/s, critic_loss=-16.4, gen_loss=110]\n",
      "Epoch [9/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:51<00:00,  1.64it/s, critic_loss=-27.8, gen_loss=136]\n",
      "Epoch [10/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:51<00:00,  1.64it/s, critic_loss=-22.8, gen_loss=138]\n",
      "Epoch [11/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:51<00:00,  1.64it/s, critic_loss=-105, gen_loss=138] \n",
      "Epoch [12/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:52<00:00,  1.64it/s, critic_loss=-20, gen_loss=161]   \n",
      "Epoch [13/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:53<00:00,  1.63it/s, critic_loss=-16.9, gen_loss=156] \n",
      "Epoch [14/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:51<00:00,  1.64it/s, critic_loss=-13.5, gen_loss=167]\n",
      "Epoch [15/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:52<00:00,  1.64it/s, critic_loss=-11.7, gen_loss=162]\n",
      "Epoch [16/100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:51<00:00,  1.64it/s, critic_loss=-18.1, gen_loss=173]\n",
      "Epoch [17/100]:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 409/576 [04:11<01:42,  1.63it/s, critic_loss=-9.64, gen_loss=162] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 151\u001b[0m\n\u001b[0;32m    148\u001b[0m     loss_gen\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    149\u001b[0m     opt_gen\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 151\u001b[0m     loop\u001b[38;5;241m.\u001b[39mset_postfix(critic_loss\u001b[38;5;241m=\u001b[39m\u001b[43mloss_critic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, gen_loss\u001b[38;5;241m=\u001b[39mloss_gen\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    154\u001b[0m     fake \u001b[38;5;241m=\u001b[39m gen(fixed_noise)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import grad\n",
    "\n",
    "# ========== Setup ==========\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_size = 128\n",
    "z_dim = 128\n",
    "batch_size = 64\n",
    "lambda_gp = 5\n",
    "num_epochs = 100\n",
    "lr = 1e-4  # Increased for faster and stable convergence\n",
    "critic_iterations = 2\n",
    "\n",
    "# ========== Transforms ==========\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])\n",
    "\n",
    "# ========== Safe Dataset Loader ==========\n",
    "class SafeImageFolder(ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        try:\n",
    "            sample = self.loader(path)\n",
    "        except UnidentifiedImageError:\n",
    "            sample = Image.new(\"L\", (128, 128))\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, target\n",
    "\n",
    "dataset_path = \"C:/College/Projects/X-RayComparison/Data/train\"\n",
    "dataset = SafeImageFolder(root=dataset_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "# ========== Generator ==========\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=128, img_channels=1, features_g=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            self._block(z_dim, features_g * 16, 4, 1, 0),  # 4x4\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # 8x8\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # 16x16\n",
    "            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # 32x32\n",
    "            self._block(features_g * 2, features_g, 4, 2, 1),  # 64x64\n",
    "            nn.ConvTranspose2d(features_g, img_channels, 4, 2, 1),  # 128x128\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# ========== Critic ==========\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, img_channels=1, features_d=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, features_d, 4, 2, 1),  # 64x64\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            self._block(features_d, features_d * 2, 4, 2, 1),  # 32x32\n",
    "            self._block(features_d * 2, features_d * 4, 4, 2, 1),  # 16x16\n",
    "            self._block(features_d * 4, features_d * 8, 4, 2, 1),  # 8x8\n",
    "            self._block(features_d * 8, features_d * 16, 4, 2, 1),  # 4x4\n",
    "\n",
    "            nn.Conv2d(features_d * 16, 1, 4, 1, 0),  # 1x1\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.InstanceNorm2d(out_channels, affine=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).view(-1)\n",
    "\n",
    "# ========== Gradient Penalty ==========\n",
    "def gradient_penalty(critic, real, fake, device):\n",
    "    batch_size, c, h, w = real.shape\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1, device=device).expand_as(real)\n",
    "    interpolated = (alpha * real + (1 - alpha) * fake).requires_grad_(True)\n",
    "    mixed_scores = critic(interpolated)\n",
    "    gradients = grad(outputs=mixed_scores, inputs=interpolated,\n",
    "                     grad_outputs=torch.ones_like(mixed_scores),\n",
    "                     create_graph=True, retain_graph=True)[0]\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    return ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "# ========== Initialize ==========\n",
    "gen = Generator(z_dim=z_dim).to(device)\n",
    "critic = Critic().to(device)\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=2e-4, betas=(0.0, 0.9))\n",
    "opt_critic = torch.optim.Adam(critic.parameters(), lr=1e-4, betas=(0.0, 0.9))\n",
    "\n",
    "\n",
    "os.makedirs(\"generated_samples\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "fixed_noise = torch.randn(64, z_dim, 1, 1, device=device)\n",
    "\n",
    "# ========== Training Loop ==========\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(dataloader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", leave=True)\n",
    "    for batch_idx, (real, _) in enumerate(loop):\n",
    "        real = real.to(device)\n",
    "        cur_batch_size = real.size(0)\n",
    "\n",
    "        # === Train Critic ===\n",
    "        for _ in range(critic_iterations):\n",
    "            noise = torch.randn(cur_batch_size, z_dim, 1, 1, device=device)\n",
    "            fake = gen(noise)\n",
    "            critic_real = critic(real)\n",
    "            critic_fake = critic(fake.detach())\n",
    "            gp = gradient_penalty(critic, real, fake, device)\n",
    "            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake)) + lambda_gp * gp\n",
    "\n",
    "            opt_critic.zero_grad()\n",
    "            loss_critic.backward()\n",
    "            opt_critic.step()\n",
    "\n",
    "        # === Train Generator ===\n",
    "        noise = torch.randn(cur_batch_size, z_dim, 1, 1, device=device)\n",
    "        fake = gen(noise)\n",
    "        output = critic(fake)\n",
    "        loss_gen = -torch.mean(output)\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        loop.set_postfix(critic_loss=loss_critic.item(), gen_loss=loss_gen.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fake = gen(fixed_noise)\n",
    "        utils.save_image(fake, f\"generated_samples/epoch_{epoch+1}.png\", normalize=True, nrow=8)\n",
    "    torch.save(gen.state_dict(), f\"generator_epoch_{epoch+1}.pth\")\n",
    "    torch.save(critic.state_dict(), f\"critic_epoch_{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bccd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.utils as utils\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import grad\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "# Parameters\n",
    "image_size = 128\n",
    "batch_size = 64\n",
    "z_dim = 128\n",
    "lr_gen = 2e-4\n",
    "lr_critic = 1e-4\n",
    "beta1, beta2 = 0.0, 0.9\n",
    "critic_iter = 2\n",
    "lambda_gp = 5\n",
    "num_epochs = 100\n",
    "\n",
    "# Dataset and Dataloader\n",
    "dataset = datasets.ImageFolder(\n",
    "    root=\"./Data/train\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Generator\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, 512, 4, 1, 0),      # -> (512, 4, 4)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),         # -> (256, 8, 8)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),         # -> (128, 16, 16)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),          # -> (64, 32, 32)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),           # -> (32, 64, 64)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(32, 1, 4, 2, 1),            # -> (1, 128, 128)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            utils.spectral_norm(nn.Conv2d(1, 64, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            utils.spectral_norm(nn.Conv2d(64, 128, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            utils.spectral_norm(nn.Conv2d(128, 256, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            utils.spectral_norm(nn.Conv2d(256, 512, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            utils.spectral_norm(nn.Conv2d(512, 1, 4, 1, 0))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Gradient Penalty\n",
    "def gradient_penalty(critic, real, fake, device):\n",
    "    batch_size = real.size(0)\n",
    "    epsilon = torch.rand((batch_size, 1, 1, 1), device=device)\n",
    "    interpolated = epsilon * real + (1 - epsilon) * fake\n",
    "    interpolated.requires_grad_(True)\n",
    "\n",
    "    mixed_scores = critic(interpolated)\n",
    "    grad_outputs = torch.ones_like(mixed_scores)\n",
    "\n",
    "    gradients = grad(\n",
    "        outputs=mixed_scores,\n",
    "        inputs=interpolated,\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "\n",
    "    gradients = gradients.reshape(batch_size, -1)  # Fix here\n",
    "    gp = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gp\n",
    "\n",
    "\n",
    "\n",
    "# Training Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gen = Generator(z_dim).to(device)\n",
    "gen.apply(weights_init)\n",
    "critic = Critic().to(device)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr_gen, betas=(beta1, beta2))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=lr_critic, betas=(beta1, beta2))\n",
    "\n",
    "fixed_noise = torch.randn(64, z_dim, 1, 1).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32647301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "noise = torch.randn(1, z_dim, 1, 1).to(device)\n",
    "fake = gen(noise)\n",
    "print(fake.shape)  # should be torch.Size([1, 1, 128, 128])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef6a0c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100] Batch 0/576                 Loss D: 2.2373, loss G: 0.4114\n",
      "Epoch [0/100] Batch 100/576                 Loss D: -3.8755, loss G: 2.1199\n",
      "Epoch [0/100] Batch 200/576                 Loss D: -3.0142, loss G: 2.6960\n",
      "Epoch [0/100] Batch 300/576                 Loss D: -0.9504, loss G: 1.1503\n",
      "Epoch [0/100] Batch 400/576                 Loss D: -0.3754, loss G: 0.2039\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train Critic\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(critic_iter):\n\u001b[1;32m---> 10\u001b[0m     noise \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     fake \u001b[38;5;241m=\u001b[39m gen(noise)\n\u001b[0;32m     13\u001b[0m     critic_real \u001b[38;5;241m=\u001b[39m critic(real)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real, _) in enumerate(dataloader):\n",
    "        real = real.to(device)\n",
    "        real += 0.01 * torch.randn_like(real)  # Add small noise to real images\n",
    "        cur_batch_size = real.size(0)\n",
    "\n",
    "        # Train Critic\n",
    "        for _ in range(critic_iter):\n",
    "            noise = torch.randn(cur_batch_size, z_dim, 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "\n",
    "            critic_real = critic(real).view(-1)\n",
    "            critic_fake = critic(fake.detach()).view(-1)\n",
    "            gp = gradient_penalty(critic, real, fake, device)\n",
    "            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake)) + lambda_gp * gp\n",
    "\n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True)\n",
    "            opt_critic.step()\n",
    "\n",
    "        # Train Generator\n",
    "        noise = torch.randn(cur_batch_size, z_dim, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "        gen_loss = -torch.mean(critic(fake))\n",
    "\n",
    "        gen.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}] Batch {i}/{len(dataloader)} \\\n",
    "                Loss D: {loss_critic.item():.4f}, loss G: {gen_loss.item():.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fake_images = gen(fixed_noise)\n",
    "        vutils.save_image(fake_images.detach(), f\"output/fake_epoch_{epoch:03d}.png\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f55dd4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [04:09<00:00,  2.31it/s, Loss_D=-0.1812, Loss_G=-0.5009]\n",
      "Epoch 2/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0898, Loss_G=-0.9866]\n",
      "Epoch 3/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0297, Loss_G=-0.9117]\n",
      "Epoch 4/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1004, Loss_G=-1.3933]\n",
      "Epoch 5/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.54it/s, Loss_D=-0.1256, Loss_G=-1.9822]\n",
      "Epoch 6/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.3410, Loss_G=-1.4743]\n",
      "Epoch 7/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:46<00:00,  2.54it/s, Loss_D=-0.1156, Loss_G=-0.8499]\n",
      "Epoch 8/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.54it/s, Loss_D=0.1167, Loss_G=-1.0588] \n",
      "Epoch 9/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.54it/s, Loss_D=-0.0921, Loss_G=-0.6659]\n",
      "Epoch 10/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0592, Loss_G=-1.2430]\n",
      "Epoch 11/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0341, Loss_G=-1.2738]\n",
      "Epoch 12/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1415, Loss_G=-1.6636]\n",
      "Epoch 13/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:48<00:00,  2.52it/s, Loss_D=-0.1626, Loss_G=-1.2928]\n",
      "Epoch 14/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:48<00:00,  2.53it/s, Loss_D=-0.2854, Loss_G=-1.4115]\n",
      "Epoch 15/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.2807, Loss_G=-0.7326]\n",
      "Epoch 16/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=0.0207, Loss_G=-1.0732] \n",
      "Epoch 17/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.4526, Loss_G=-0.7359]\n",
      "Epoch 18/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1543, Loss_G=-0.4980]\n",
      "Epoch 19/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0032, Loss_G=-0.5861]\n",
      "Epoch 20/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1016, Loss_G=-0.3332]\n",
      "Epoch 21/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=0.0058, Loss_G=-0.7764] \n",
      "Epoch 22/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.2122, Loss_G=-0.2145]\n",
      "Epoch 23/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=0.0051, Loss_G=-0.7941] \n",
      "Epoch 24/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.3362, Loss_G=0.1103] \n",
      "Epoch 25/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=0.0488, Loss_G=0.0261]  \n",
      "Epoch 26/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0776, Loss_G=-0.6931]\n",
      "Epoch 27/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1372, Loss_G=-0.4225]\n",
      "Epoch 28/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0882, Loss_G=-0.1422]\n",
      "Epoch 29/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1162, Loss_G=-0.1116]\n",
      "Epoch 30/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1265, Loss_G=-0.0705]\n",
      "Epoch 31/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0505, Loss_G=-0.0909]\n",
      "Epoch 32/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:48<00:00,  2.53it/s, Loss_D=-0.0384, Loss_G=0.2093] \n",
      "Epoch 33/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1651, Loss_G=0.4370] \n",
      "Epoch 34/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1255, Loss_G=0.0864] \n",
      "Epoch 35/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1721, Loss_G=0.7484] \n",
      "Epoch 36/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0550, Loss_G=0.4275] \n",
      "Epoch 37/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0591, Loss_G=0.1509] \n",
      "Epoch 38/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0591, Loss_G=0.0546] \n",
      "Epoch 39/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0064, Loss_G=0.2225] \n",
      "Epoch 40/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1111, Loss_G=0.5695] \n",
      "Epoch 41/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1604, Loss_G=0.1815] \n",
      "Epoch 42/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0536, Loss_G=0.5157] \n",
      "Epoch 43/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1874, Loss_G=0.7205] \n",
      "Epoch 44/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0904, Loss_G=0.7854] \n",
      "Epoch 45/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=0.0420, Loss_G=0.0934]  \n",
      "Epoch 46/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0848, Loss_G=0.5599] \n",
      "Epoch 47/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=0.0361, Loss_G=-0.5039] \n",
      "Epoch 48/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0846, Loss_G=0.2418] \n",
      "Epoch 49/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=0.0197, Loss_G=0.2191]  \n",
      "Epoch 50/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0763, Loss_G=0.0941] \n",
      "Epoch 51/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0642, Loss_G=0.6126] \n",
      "Epoch 52/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0971, Loss_G=-0.2784]\n",
      "Epoch 53/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0481, Loss_G=0.0810] \n",
      "Epoch 54/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.2998, Loss_G=0.9140] \n",
      "Epoch 55/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.2413, Loss_G=-0.1535]\n",
      "Epoch 56/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.4604, Loss_G=1.1267] \n",
      "Epoch 57/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0687, Loss_G=0.4624] \n",
      "Epoch 58/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1066, Loss_G=0.8620] \n",
      "Epoch 59/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:48<00:00,  2.53it/s, Loss_D=-0.0514, Loss_G=-0.0752]\n",
      "Epoch 60/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=0.0720, Loss_G=-0.0391] \n",
      "Epoch 61/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=0.0494, Loss_G=0.5203]  \n",
      "Epoch 62/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0513, Loss_G=0.2823] \n",
      "Epoch 63/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1666, Loss_G=-0.2041]\n",
      "Epoch 64/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0610, Loss_G=0.2608] \n",
      "Epoch 65/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0640, Loss_G=0.3792] \n",
      "Epoch 66/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.2171, Loss_G=0.3927] \n",
      "Epoch 67/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.2613, Loss_G=0.9764] \n",
      "Epoch 68/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=0.0313, Loss_G=0.3717]  \n",
      "Epoch 69/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1174, Loss_G=0.2257] \n",
      "Epoch 70/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0839, Loss_G=0.4925] \n",
      "Epoch 71/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0371, Loss_G=0.4062] \n",
      "Epoch 72/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0672, Loss_G=0.2614] \n",
      "Epoch 73/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:48<00:00,  2.52it/s, Loss_D=0.0519, Loss_G=0.5132]  \n",
      "Epoch 74/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0636, Loss_G=-0.1609]\n",
      "Epoch 75/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0441, Loss_G=0.6134] \n",
      "Epoch 76/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:48<00:00,  2.53it/s, Loss_D=-0.0433, Loss_G=0.3388] \n",
      "Epoch 77/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=0.0041, Loss_G=0.5864]  \n",
      "Epoch 78/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1047, Loss_G=0.2765] \n",
      "Epoch 79/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0211, Loss_G=0.6868] \n",
      "Epoch 80/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0478, Loss_G=0.4115] \n",
      "Epoch 81/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0621, Loss_G=0.4306] \n",
      "Epoch 82/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1227, Loss_G=0.6267] \n",
      "Epoch 83/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:48<00:00,  2.53it/s, Loss_D=-0.0385, Loss_G=0.2514] \n",
      "Epoch 84/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1485, Loss_G=0.6903] \n",
      "Epoch 85/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:48<00:00,  2.53it/s, Loss_D=-0.0844, Loss_G=0.4460] \n",
      "Epoch 86/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0249, Loss_G=0.5144] \n",
      "Epoch 87/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0506, Loss_G=0.1861] \n",
      "Epoch 88/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1138, Loss_G=0.4678] \n",
      "Epoch 89/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=0.0069, Loss_G=0.4345]  \n",
      "Epoch 90/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0768, Loss_G=0.3425] \n",
      "Epoch 91/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:48<00:00,  2.53it/s, Loss_D=-0.2093, Loss_G=-0.1697]\n",
      "Epoch 92/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0311, Loss_G=0.3816] \n",
      "Epoch 93/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0988, Loss_G=0.2852] \n",
      "Epoch 94/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0503, Loss_G=0.1178] \n",
      "Epoch 95/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:48<00:00,  2.53it/s, Loss_D=-0.0785, Loss_G=0.4080] \n",
      "Epoch 96/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=0.0144, Loss_G=0.0831]  \n",
      "Epoch 97/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.1324, Loss_G=0.5792] \n",
      "Epoch 98/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=-0.0102, Loss_G=0.2821] \n",
      "Epoch 99/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:47<00:00,  2.53it/s, Loss_D=0.0219, Loss_G=0.4939]  \n",
      "Epoch 100/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:48<00:00,  2.53it/s, Loss_D=-0.0501, Loss_G=0.1378] \n"
     ]
    }
   ],
   "source": [
    "# Training Loop with tqdm\n",
    "for epoch in range(num_epochs):\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for i, (real, _) in pbar:\n",
    "        real = real.to(device)\n",
    "        real += 0.01 * torch.randn_like(real)  # Add small noise to real images\n",
    "        cur_batch_size = real.size(0)\n",
    "\n",
    "        # Train Critic\n",
    "        for _ in range(critic_iter):\n",
    "            noise = torch.randn(cur_batch_size, z_dim, 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "\n",
    "            critic_real = critic(real).view(-1)\n",
    "            critic_fake = critic(fake.detach()).view(-1)\n",
    "            gp = gradient_penalty(critic, real, fake, device)\n",
    "            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake)) + lambda_gp * gp\n",
    "\n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True)\n",
    "            opt_critic.step()\n",
    "\n",
    "        # Train Generator\n",
    "        noise = torch.randn(cur_batch_size, z_dim, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "        gen_loss = -torch.mean(critic(fake))\n",
    "\n",
    "        gen.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # tqdm progress\n",
    "        pbar.set_postfix({\n",
    "            'Loss_D': f\"{loss_critic.item():.4f}\",\n",
    "            'Loss_G': f\"{gen_loss.item():.4f}\"\n",
    "        })\n",
    "\n",
    "    # Save generated samples after each epoch\n",
    "    with torch.no_grad():\n",
    "        fake_images = gen(fixed_noise)\n",
    "        os.makedirs(\"output\", exist_ok=True)\n",
    "        vutils.save_image(fake_images.detach(), f\"output/fake_epoch_{epoch:03d}.png\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a787744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapik\\AppData\\Local\\Temp\\ipykernel_53076\\2196431190.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Generator:\n\tMissing key(s) in state_dict: \"gen.0.weight\", \"gen.0.bias\", \"gen.1.weight\", \"gen.1.bias\", \"gen.1.running_mean\", \"gen.1.running_var\", \"gen.3.weight\", \"gen.3.bias\", \"gen.4.weight\", \"gen.4.bias\", \"gen.4.running_mean\", \"gen.4.running_var\", \"gen.6.weight\", \"gen.6.bias\", \"gen.7.weight\", \"gen.7.bias\", \"gen.7.running_mean\", \"gen.7.running_var\", \"gen.9.weight\", \"gen.9.bias\", \"gen.10.weight\", \"gen.10.bias\", \"gen.10.running_mean\", \"gen.10.running_var\", \"gen.12.weight\", \"gen.12.bias\", \"gen.13.weight\", \"gen.13.bias\", \"gen.13.running_mean\", \"gen.13.running_var\", \"gen.15.weight\", \"gen.15.bias\". \n\tUnexpected key(s) in state_dict: \"model.0.weight\", \"model.0.bias\", \"model.1.weight\", \"model.1.bias\", \"model.1.running_mean\", \"model.1.running_var\", \"model.1.num_batches_tracked\", \"model.3.weight\", \"model.3.bias\", \"model.4.weight\", \"model.4.bias\", \"model.4.running_mean\", \"model.4.running_var\", \"model.4.num_batches_tracked\", \"model.6.weight\", \"model.6.bias\", \"model.7.weight\", \"model.7.bias\", \"model.7.running_mean\", \"model.7.running_var\", \"model.7.num_batches_tracked\", \"model.9.weight\", \"model.9.bias\", \"model.10.weight\", \"model.10.bias\", \"model.10.running_mean\", \"model.10.running_var\", \"model.10.num_batches_tracked\", \"model.12.weight\", \"model.12.bias\", \"model.13.weight\", \"model.13.bias\", \"model.13.running_mean\", \"model.13.running_var\", \"model.13.num_batches_tracked\", \"model.15.weight\", \"model.15.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(checkpoint_path, map_location\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# print(checkpoint['critic_state_dict'])\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenerator_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m critic\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcritic_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m opt_gen\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt_gen_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2580\u001b[0m             ),\n\u001b[0;32m   2581\u001b[0m         )\n\u001b[0;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2587\u001b[0m         )\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Generator:\n\tMissing key(s) in state_dict: \"gen.0.weight\", \"gen.0.bias\", \"gen.1.weight\", \"gen.1.bias\", \"gen.1.running_mean\", \"gen.1.running_var\", \"gen.3.weight\", \"gen.3.bias\", \"gen.4.weight\", \"gen.4.bias\", \"gen.4.running_mean\", \"gen.4.running_var\", \"gen.6.weight\", \"gen.6.bias\", \"gen.7.weight\", \"gen.7.bias\", \"gen.7.running_mean\", \"gen.7.running_var\", \"gen.9.weight\", \"gen.9.bias\", \"gen.10.weight\", \"gen.10.bias\", \"gen.10.running_mean\", \"gen.10.running_var\", \"gen.12.weight\", \"gen.12.bias\", \"gen.13.weight\", \"gen.13.bias\", \"gen.13.running_mean\", \"gen.13.running_var\", \"gen.15.weight\", \"gen.15.bias\". \n\tUnexpected key(s) in state_dict: \"model.0.weight\", \"model.0.bias\", \"model.1.weight\", \"model.1.bias\", \"model.1.running_mean\", \"model.1.running_var\", \"model.1.num_batches_tracked\", \"model.3.weight\", \"model.3.bias\", \"model.4.weight\", \"model.4.bias\", \"model.4.running_mean\", \"model.4.running_var\", \"model.4.num_batches_tracked\", \"model.6.weight\", \"model.6.bias\", \"model.7.weight\", \"model.7.bias\", \"model.7.running_mean\", \"model.7.running_var\", \"model.7.num_batches_tracked\", \"model.9.weight\", \"model.9.bias\", \"model.10.weight\", \"model.10.bias\", \"model.10.running_mean\", \"model.10.running_var\", \"model.10.num_batches_tracked\", \"model.12.weight\", \"model.12.bias\", \"model.13.weight\", \"model.13.bias\", \"model.13.running_mean\", \"model.13.running_var\", \"model.13.num_batches_tracked\", \"model.15.weight\", \"model.15.bias\". "
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "checkpoint_path = \"checkpoints/checkpoint_epoch_150.pth\"\n",
    "\n",
    "# Resume from checkpoint if available\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    # print(checkpoint['critic_state_dict'])\n",
    "    gen.load_state_dict(checkpoint['generator_state_dict'])\n",
    "    critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "    opt_gen.load_state_dict(checkpoint['opt_gen_state_dict'])\n",
    "    opt_critic.load_state_dict(checkpoint['opt_critic_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"Resuming training from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"Starting training from scratch.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdb1ddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [101/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:46<00:00,  2.55it/s, critic_loss=-0.0275, gen_loss=0.826]    \n",
      "Epoch [102/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:35<00:00,  2.67it/s, critic_loss=-0.0659, gen_loss=0.741]   \n",
      "Epoch [103/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:39<00:00,  2.63it/s, critic_loss=-0.0964, gen_loss=0.939]  \n",
      "Epoch [104/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:50<00:00,  2.50it/s, critic_loss=-0.0534, gen_loss=0.379]   \n",
      "Epoch [105/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:55<00:00,  2.45it/s, critic_loss=-0.0693, gen_loss=0.349]   \n",
      "Epoch [106/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [04:49<00:00,  1.99it/s, critic_loss=-0.157, gen_loss=0.0063]  \n",
      "Epoch [107/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:34<00:00,  2.68it/s, critic_loss=-0.0463, gen_loss=0.356]  \n",
      "Epoch [108/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:35<00:00,  2.67it/s, critic_loss=-0.152, gen_loss=0.81]    \n",
      "Epoch [109/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:36<00:00,  2.66it/s, critic_loss=-0.0836, gen_loss=0.902]  \n",
      "Epoch [110/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:35<00:00,  2.67it/s, critic_loss=-0.0409, gen_loss=0.635]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [111/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:35<00:00,  2.67it/s, critic_loss=-0.0456, gen_loss=0.773]  \n",
      "Epoch [112/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:34<00:00,  2.69it/s, critic_loss=-0.244, gen_loss=0.215]   \n",
      "Epoch [113/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:35<00:00,  2.68it/s, critic_loss=-0.0533, gen_loss=0.512]  \n",
      "Epoch [114/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:38<00:00,  2.64it/s, critic_loss=0.0377, gen_loss=0.978]   \n",
      "Epoch [115/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:44<00:00,  2.56it/s, critic_loss=-0.0321, gen_loss=0.843]  \n",
      "Epoch [116/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:38<00:00,  2.63it/s, critic_loss=-0.0742, gen_loss=0.79]   \n",
      "Epoch [117/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:34<00:00,  2.69it/s, critic_loss=-0.0543, gen_loss=1.01]    \n",
      "Epoch [118/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:33<00:00,  2.70it/s, critic_loss=-0.116, gen_loss=1.02]    \n",
      "Epoch [119/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:33<00:00,  2.70it/s, critic_loss=0.0153, gen_loss=0.584]   \n",
      "Epoch [120/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:32<00:00,  2.71it/s, critic_loss=-0.0566, gen_loss=0.523]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [121/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:33<00:00,  2.70it/s, critic_loss=-0.0346, gen_loss=0.838]  \n",
      "Epoch [122/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:34<00:00,  2.69it/s, critic_loss=-0.00544, gen_loss=0.567] \n",
      "Epoch [123/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:34<00:00,  2.69it/s, critic_loss=-0.0951, gen_loss=0.821]  \n",
      "Epoch [124/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:33<00:00,  2.70it/s, critic_loss=-0.0611, gen_loss=0.483]  \n",
      "Epoch [125/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:33<00:00,  2.70it/s, critic_loss=-0.0722, gen_loss=1.03]   \n",
      "Epoch [126/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:34<00:00,  2.68it/s, critic_loss=-0.0205, gen_loss=0.59]   \n",
      "Epoch [127/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:33<00:00,  2.70it/s, critic_loss=-0.0372, gen_loss=0.544]  \n",
      "Epoch [128/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:33<00:00,  2.70it/s, critic_loss=0.00157, gen_loss=1.18]   \n",
      "Epoch [129/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:33<00:00,  2.70it/s, critic_loss=-0.0671, gen_loss=1.06]     \n",
      "Epoch [130/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:33<00:00,  2.70it/s, critic_loss=-0.114, gen_loss=1.22]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [131/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:33<00:00,  2.70it/s, critic_loss=0.0335, gen_loss=0.69]    \n",
      "Epoch [132/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:32<00:00,  2.71it/s, critic_loss=-0.12, gen_loss=0.716]    \n",
      "Epoch [133/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:32<00:00,  2.71it/s, critic_loss=-0.11, gen_loss=1.28]     \n",
      "Epoch [134/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:33<00:00,  2.70it/s, critic_loss=0.0386, gen_loss=0.701]   \n",
      "Epoch [135/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:40<00:00,  2.61it/s, critic_loss=-0.00273, gen_loss=0.28]  \n",
      "Epoch [136/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:41<00:00,  2.60it/s, critic_loss=-0.0863, gen_loss=0.601]   \n",
      "Epoch [137/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:36<00:00,  2.66it/s, critic_loss=-0.17, gen_loss=0.461]    \n",
      "Epoch [138/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [04:09<00:00,  2.31it/s, critic_loss=-0.0235, gen_loss=0.848]  \n",
      "Epoch [139/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [05:34<00:00,  1.72it/s, critic_loss=-0.0407, gen_loss=0.614]  \n",
      "Epoch [140/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [04:17<00:00,  2.24it/s, critic_loss=-0.0324, gen_loss=0.277]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [141/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [04:01<00:00,  2.39it/s, critic_loss=-0.0329, gen_loss=0.452]  \n",
      "Epoch [142/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:44<00:00,  2.57it/s, critic_loss=0.0326, gen_loss=0.803]   \n",
      "Epoch [143/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:30<00:00,  2.74it/s, critic_loss=-0.181, gen_loss=0.909]    \n",
      "Epoch [144/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.0974, gen_loss=0.708]  \n",
      "Epoch [145/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:30<00:00,  2.74it/s, critic_loss=-0.0284, gen_loss=0.581]  \n",
      "Epoch [146/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:30<00:00,  2.74it/s, critic_loss=-0.107, gen_loss=0.429]     \n",
      "Epoch [147/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:30<00:00,  2.74it/s, critic_loss=-0.0979, gen_loss=0.608]  \n",
      "Epoch [148/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:30<00:00,  2.74it/s, critic_loss=0.0423, gen_loss=0.583]   \n",
      "Epoch [149/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:30<00:00,  2.74it/s, critic_loss=-0.0502, gen_loss=0.558] \n",
      "Epoch [150/150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.0534, gen_loss=0.709]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 150\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# === Setup ===\n",
    "fixed_noise = torch.randn(64, z_dim, 1, 1).to(device)\n",
    "total_epochs = start_epoch + 50\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"generated_samples\", exist_ok=True)\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "for epoch in range(start_epoch, total_epochs):\n",
    "    loop = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch [{epoch+1}/{total_epochs}]\")\n",
    "    gen.train()\n",
    "    critic.train()\n",
    "\n",
    "    for batch_idx, (real, _) in loop:\n",
    "        real = real.to(device)\n",
    "        real += 0.01 * torch.randn_like(real)  # Label smoothing\n",
    "        cur_batch_size = real.size(0)\n",
    "\n",
    "        # === Train Critic ===\n",
    "        for _ in range(critic_iterations):\n",
    "            noise = torch.randn(cur_batch_size, z_dim, 1, 1, device=device)\n",
    "            fake = gen(noise)\n",
    "\n",
    "            critic_real = critic(real).view(-1)\n",
    "            critic_fake = critic(fake.detach()).view(-1)\n",
    "\n",
    "            gp = gradient_penalty(critic, real, fake, device)\n",
    "            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake)) + lambda_gp * gp\n",
    "\n",
    "            opt_critic.zero_grad()\n",
    "            loss_critic.backward()\n",
    "            opt_critic.step()\n",
    "\n",
    "        # === Train Generator ===\n",
    "        noise = torch.randn(cur_batch_size, z_dim, 1, 1, device=device)\n",
    "        fake = gen(noise)\n",
    "        gen_loss = -torch.mean(critic(fake))\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        loop.set_postfix(critic_loss=loss_critic.item(), gen_loss=gen_loss.item())\n",
    "\n",
    "    # === Save generated image every epoch ===\n",
    "    with torch.no_grad():\n",
    "        fake_images = gen(fixed_noise)\n",
    "        vutils.save_image(fake_images, f\"output/fake_epoch_{epoch+1:03d}.png\", normalize=True, nrow=8)\n",
    "\n",
    "        # Also save for generated_samples (optional pretty grid format)\n",
    "        fake_grid = make_grid(fake_images, normalize=True, nrow=8)\n",
    "        save_image(fake_grid, f\"generated_samples/sample_epoch_{epoch+1:03d}.png\")\n",
    "\n",
    "    # === Save checkpoint every 10 epochs ===\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(gen.state_dict(), f\"checkpoints/generator_epoch_{epoch+1}.pth\")\n",
    "        torch.save(critic.state_dict(), f\"checkpoints/critic_epoch_{epoch+1}.pth\")\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'generator_state_dict': gen.state_dict(),\n",
    "            'critic_state_dict': critic.state_dict(),\n",
    "            'opt_gen_state_dict': opt_gen.state_dict(),\n",
    "            'opt_critic_state_dict': opt_critic.state_dict(),\n",
    "        }, f\"checkpoints/checkpoint_epoch_{epoch+1}.pth\")\n",
    "\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ef2f63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Resumed training from epoch 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapik\\AppData\\Local\\Temp\\ipykernel_25548\\2585658464.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "checkpoint_path = \"checkpoints/checkpoint_epoch_150.pth\"\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    try:\n",
    "        gen.load_state_dict(checkpoint['generator_state_dict'])\n",
    "        critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "        opt_gen.load_state_dict(checkpoint['opt_gen_state_dict'])\n",
    "        opt_critic.load_state_dict(checkpoint['opt_critic_state_dict'])\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error loading model states. Check model architecture and z_dim.\")\n",
    "        print(str(e))\n",
    "        raise\n",
    "    \n",
    "    gen.to(device)\n",
    "    critic.to(device)\n",
    "    \n",
    "    start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "\n",
    "    # Optionally restore random state if you saved it\n",
    "    if 'random_state' in checkpoint:\n",
    "        torch.set_rng_state(checkpoint['random_state'])\n",
    "\n",
    "    print(f\"âœ… Resumed training from epoch {start_epoch}\")\n",
    "    \n",
    "    # If you stored loss values:\n",
    "    if 'gen_loss' in checkpoint and 'critic_loss' in checkpoint:\n",
    "        print(f\"Previous losses - Generator: {checkpoint['gen_loss']:.4f}, Critic: {checkpoint['critic_loss']:.4f}\")\n",
    "else:\n",
    "    print(\"ðŸš€ Starting training from scratch.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b75cef9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapik\\AppData\\Local\\Temp\\ipykernel_25548\\287900577.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gen.load_state_dict(torch.load(gen_path, map_location=device))\n",
      "C:\\Users\\kapik\\AppData\\Local\\Temp\\ipykernel_25548\\287900577.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  critic.load_state_dict(torch.load(critic_path, map_location=device))\n",
      "C:\\Users\\kapik\\AppData\\Local\\Temp\\ipykernel_25548\\287900577.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from checkpoint at epoch 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [151/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:55<00:00,  2.45it/s, critic_loss=0.0155, gen_loss=0.801]   \n",
      "Epoch [152/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:28<00:00,  2.76it/s, critic_loss=-0.146, gen_loss=0.407]     \n",
      "Epoch [153/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:28<00:00,  2.76it/s, critic_loss=-0.108, gen_loss=0.911]   \n",
      "Epoch [154/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:28<00:00,  2.76it/s, critic_loss=0.03, gen_loss=0.512]     \n",
      "Epoch [155/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.0979, gen_loss=0.754]  \n",
      "Epoch [156/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.0131, gen_loss=0.474]   \n",
      "Epoch [157/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.078, gen_loss=0.513]    \n",
      "Epoch [158/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.096, gen_loss=1.3]     \n",
      "Epoch [159/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.14, gen_loss=1.06]       \n",
      "Epoch [160/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:31<00:00,  2.72it/s, critic_loss=-0.0854, gen_loss=0.926]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [161/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:31<00:00,  2.73it/s, critic_loss=0.00757, gen_loss=0.813]  \n",
      "Epoch [162/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.0768, gen_loss=0.583]  \n",
      "Epoch [163/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:30<00:00,  2.74it/s, critic_loss=-0.0737, gen_loss=0.955]    \n",
      "Epoch [164/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:30<00:00,  2.73it/s, critic_loss=-0.16, gen_loss=0.838]    \n",
      "Epoch [165/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:28<00:00,  2.76it/s, critic_loss=-0.035, gen_loss=0.88]    \n",
      "Epoch [166/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:28<00:00,  2.76it/s, critic_loss=0.0304, gen_loss=0.974]   \n",
      "Epoch [167/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.76it/s, critic_loss=-0.013, gen_loss=0.547]   \n",
      "Epoch [168/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:28<00:00,  2.76it/s, critic_loss=-0.094, gen_loss=0.68]    \n",
      "Epoch [169/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.76it/s, critic_loss=-0.0574, gen_loss=0.835]  \n",
      "Epoch [170/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=0.0238, gen_loss=0.634]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [171/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.74it/s, critic_loss=-0.00623, gen_loss=0.761] \n",
      "Epoch [172/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:30<00:00,  2.74it/s, critic_loss=-0.0896, gen_loss=-0.00651]\n",
      "Epoch [173/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:30<00:00,  2.74it/s, critic_loss=0.00226, gen_loss=0.521]  \n",
      "Epoch [174/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.74it/s, critic_loss=-0.0328, gen_loss=0.553]   \n",
      "Epoch [175/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:30<00:00,  2.74it/s, critic_loss=-0.0203, gen_loss=0.727]  \n",
      "Epoch [176/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.74it/s, critic_loss=-0.0688, gen_loss=0.703]   \n",
      "Epoch [177/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:31<00:00,  2.72it/s, critic_loss=-0.0876, gen_loss=0.585]  \n",
      "Epoch [178/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:31<00:00,  2.72it/s, critic_loss=-0.076, gen_loss=0.703]   \n",
      "Epoch [179/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.74it/s, critic_loss=0.00589, gen_loss=0.818]  \n",
      "Epoch [180/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:31<00:00,  2.72it/s, critic_loss=-0.0631, gen_loss=0.973]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [181/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:32<00:00,  2.71it/s, critic_loss=0.0049, gen_loss=0.623]   \n",
      "Epoch [182/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.186, gen_loss=0.485]   \n",
      "Epoch [183/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.103, gen_loss=0.685]   \n",
      "Epoch [184/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.0805, gen_loss=1.04]   \n",
      "Epoch [185/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=0.00774, gen_loss=0.789]  \n",
      "Epoch [186/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.74it/s, critic_loss=-0.0116, gen_loss=0.884]  \n",
      "Epoch [187/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.0756, gen_loss=0.606]  \n",
      "Epoch [188/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.0371, gen_loss=0.989]  \n",
      "Epoch [189/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.116, gen_loss=1.56]    \n",
      "Epoch [190/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.0518, gen_loss=0.597]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [191/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.0772, gen_loss=0.975]  \n",
      "Epoch [192/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=0.00364, gen_loss=1.02]   \n",
      "Epoch [193/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.00239, gen_loss=0.899]  \n",
      "Epoch [194/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:31<00:00,  2.72it/s, critic_loss=-0.012, gen_loss=0.99]    \n",
      "Epoch [195/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:31<00:00,  2.72it/s, critic_loss=-0.0467, gen_loss=0.175]  \n",
      "Epoch [196/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.0579, gen_loss=0.454]  \n",
      "Epoch [197/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:30<00:00,  2.74it/s, critic_loss=-0.0455, gen_loss=0.59]   \n",
      "Epoch [198/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:32<00:00,  2.72it/s, critic_loss=-0.112, gen_loss=0.813]   \n",
      "Epoch [199/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=-0.036, gen_loss=0.656]   \n",
      "Epoch [200/200]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [03:29<00:00,  2.75it/s, critic_loss=0.0438, gen_loss=0.589]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# === Setup ===\n",
    "checkpoint_epoch = 150\n",
    "checkpoint_path = f\"checkpoints/checkpoint_epoch_{checkpoint_epoch}.pth\"\n",
    "gen_path = f\"checkpoints/generator_epoch_{checkpoint_epoch}.pth\"\n",
    "critic_path = f\"checkpoints/critic_epoch_{checkpoint_epoch}.pth\"\n",
    "\n",
    "resume = True\n",
    "z_dim = 128  # or your value\n",
    "fixed_noise = torch.randn(64, z_dim, 1, 1).to(device)\n",
    "total_epochs = checkpoint_epoch + 50  # Run 50 more epochs\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"generated_samples\", exist_ok=True)\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# === Resume Checkpoint ===\n",
    "if resume and os.path.exists(checkpoint_path):\n",
    "    print(f\"Resuming from checkpoint at epoch {checkpoint_epoch}\")\n",
    "\n",
    "    # Load model weights\n",
    "    gen.load_state_dict(torch.load(gen_path, map_location=device))\n",
    "    critic.load_state_dict(torch.load(critic_path, map_location=device))\n",
    "\n",
    "    # Load optimizer states and epoch\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    opt_gen.load_state_dict(checkpoint['opt_gen_state_dict'])\n",
    "    opt_critic.load_state_dict(checkpoint['opt_critic_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1  # resume from next epoch\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting from scratch.\")\n",
    "    start_epoch = 0\n",
    "\n",
    "# === Training Loop ===\n",
    "for epoch in range(start_epoch, total_epochs):\n",
    "    loop = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch [{epoch+1}/{total_epochs}]\")\n",
    "    gen.train()\n",
    "    critic.train()\n",
    "\n",
    "    for batch_idx, (real, _) in loop:\n",
    "        real = real.to(device)\n",
    "        real += 0.01 * torch.randn_like(real)  # Label smoothing\n",
    "        cur_batch_size = real.size(0)\n",
    "\n",
    "        # === Train Critic ===\n",
    "        for _ in range(critic_iterations):\n",
    "            noise = torch.randn(cur_batch_size, z_dim, 1, 1, device=device)\n",
    "            fake = gen(noise)\n",
    "\n",
    "            critic_real = critic(real).view(-1)\n",
    "            critic_fake = critic(fake.detach()).view(-1)\n",
    "\n",
    "            gp = gradient_penalty(critic, real, fake, device)\n",
    "            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake)) + lambda_gp * gp\n",
    "\n",
    "            opt_critic.zero_grad()\n",
    "            loss_critic.backward()\n",
    "            opt_critic.step()\n",
    "\n",
    "        # === Train Generator ===\n",
    "        noise = torch.randn(cur_batch_size, z_dim, 1, 1, device=device)\n",
    "        fake = gen(noise)\n",
    "        gen_loss = -torch.mean(critic(fake))\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        loop.set_postfix(critic_loss=loss_critic.item(), gen_loss=gen_loss.item())\n",
    "\n",
    "    # === Save generated image every epoch ===\n",
    "    with torch.no_grad():\n",
    "        fake_images = gen(fixed_noise)\n",
    "        vutils.save_image(fake_images, f\"output/fake_epoch_{epoch+1:03d}.png\", normalize=True, nrow=8)\n",
    "\n",
    "        fake_grid = make_grid(fake_images, normalize=True, nrow=8)\n",
    "        save_image(fake_grid, f\"generated_samples/sample_epoch_{epoch+1:03d}.png\")\n",
    "\n",
    "    # === Save checkpoint every 10 epochs ===\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(gen.state_dict(), f\"checkpoints/generator_epoch_{epoch+1}.pth\")\n",
    "        torch.save(critic.state_dict(), f\"checkpoints/critic_epoch_{epoch+1}.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'generator_state_dict': gen.state_dict(),\n",
    "            'critic_state_dict': critic.state_dict(),\n",
    "            'opt_gen_state_dict': opt_gen.state_dict(),\n",
    "            'opt_critic_state_dict': opt_critic.state_dict(),\n",
    "        }, f\"checkpoints/checkpoint_epoch_{epoch+1}.pth\")\n",
    "\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "487b2c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvTranspose2d(128, 512, kernel_size=(4, 4), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "print(gen.model[0])  # should show ConvTranspose2d with in_channels = z_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99d7b9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapik\\AppData\\Local\\Temp\\ipykernel_53076\\431122847.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gen.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
      "Generating Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:03<00:00,  4.01it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generator definition (must match your architecture)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, 512, 4, 1, 0),      # -> (512, 4, 4)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),         # -> (256, 8, 8)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),         # -> (128, 16, 16)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),          # -> (64, 32, 32)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),           # -> (32, 64, 64)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(32, 1, 4, 2, 1),            # -> (1, 128, 128)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# Configuration\n",
    "z_dim = 128\n",
    "checkpoint_path = r\"checkpoints\\generator_epoch_200.pth\"\n",
    "output_dir = \"generated_images\"\n",
    "num_images = 1000\n",
    "batch_size = 64\n",
    "\n",
    "# Load the generator\n",
    "gen = Generator(z_dim).to(device)\n",
    "gen.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "gen.eval()\n",
    "\n",
    "# Make output folder\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save images\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, num_images, batch_size), desc=\"Generating Images\"):\n",
    "        cur_batch_size = min(batch_size, num_images - i)\n",
    "        noise = torch.randn(cur_batch_size, z_dim, 1, 1, device=device)\n",
    "        fake_images = gen(noise)\n",
    "        fake_images = (fake_images + 1) / 2  # if Tanh was used\n",
    "\n",
    "        for j in range(cur_batch_size):\n",
    "            save_path = os.path.join(output_dir, f\"image_{i + j:04d}.png\")\n",
    "            save_image(fake_images[j], save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan-xray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
