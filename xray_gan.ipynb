{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9012ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.1\n",
      "  latest version: 25.5.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd61cc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: matplotlib in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: pillow in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: filelock in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: networkx in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision matplotlib pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fec67b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from glob import glob\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Settings\n",
    "image_size = 256\n",
    "batch_size = 64\n",
    "latent_dim = 100\n",
    "epochs = 100\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "save_dir = \"./generated\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "DATASET_ROOT = \"C:/College/Projects/X-RayComparison/Data/train/\"\n",
    "XR_TYPE = \"XR_ELBOW\"  # or XR_ELBOW, XR_HAND, etc.\n",
    "IMG_DIR = os.path.join(DATASET_ROOT, XR_TYPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db44d149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun  8 21:38:31 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   52C    P5              8W /  120W |     924MiB /   8188MiB |     13%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1912    C+G   ...nr4m\\radeonsoftware\\AMDRSSrcExt.exe      N/A      |\n",
      "|    0   N/A  N/A      9860    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     10040    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "|    0   N/A  N/A     10836    C+G   C:\\Apps\\Work\\ZenBrowser\\zen.exe             N/A      |\n",
      "|    0   N/A  N/A     12628    C+G   C:\\Windows\\System32\\NahimicSvc64.exe        N/A      |\n",
      "|    0   N/A  N/A     14100    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14124    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     15620    C+G   ...on\\136.0.3240.92\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     16028    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     16108    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     17516    C+G   C:\\Apps\\Work\\ZenBrowser\\zen.exe             N/A      |\n",
      "|    0   N/A  N/A     19320    C+G   ...ys\\WinUI3Apps\\PowerToys.Peek.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     19688    C+G   ...s\\System32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A     20016    C+G   ...werToys\\PowerToys.ColorPickerUI.exe      N/A      |\n",
      "|    0   N/A  N/A     20080    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     20120    C+G   ...\\PowerToys\\PowerToys.FancyZones.exe      N/A      |\n",
      "|    0   N/A  N/A     20188    C+G   ...ekyb3d8bbwe\\Microsoft.CmdPal.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     20804    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     20956    C+G   ...werToys\\PowerToys.PowerLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A     21216    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     24028    C+G   ...pps\\Work\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     25664    C+G   ...5.0_x64__w2gh52qy24etm\\Nahimic3.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f11ee6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should print True\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44e5237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class MURAXrayDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        # Example: root_dir = \"C:/College/Projects/X-RayComparison/Data/train\"\n",
    "        self.image_paths = glob(os.path.join(root_dir, \"**\", \"*.png\"), recursive=True)\n",
    "        if len(self.image_paths) == 0:\n",
    "            raise ValueError(f\"No .png images found in path: {root_dir}\")\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"L\")  # Convert to grayscale\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a7001eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_DIR: C:/College/Projects/X-RayComparison/Data/train/XR_ELBOW\n",
      "Folders inside: ['patient00011', 'patient00016', 'patient00026', 'patient00031', 'patient00034', 'patient00044', 'patient00069', 'patient00147', 'patient00148', 'patient00164', 'patient00180', 'patient00196', 'patient00222', 'patient00238', 'patient00266', 'patient00280', 'patient00310', 'patient00328', 'patient00354', 'patient00357', 'patient00370', 'patient00374', 'patient00377', 'patient00380', 'patient00398', 'patient00401', 'patient00404', 'patient00427', 'patient00434', 'patient00463', 'patient00466', 'patient00511', 'patient00537', 'patient00562', 'patient00643', 'patient00646', 'patient00665', 'patient00673', 'patient00707', 'patient00737', 'patient00745', 'patient00821', 'patient00876', 'patient00894', 'patient00901', 'patient00905', 'patient00918', 'patient00936', 'patient00956', 'patient00982', 'patient00990', 'patient01005', 'patient01055', 'patient01057', 'patient01079', 'patient01112', 'patient01114', 'patient01130', 'patient01134', 'patient01145', 'patient01157', 'patient01164', 'patient01211', 'patient01219', 'patient01267', 'patient01281', 'patient01292', 'patient01308', 'patient01321', 'patient01343', 'patient01362', 'patient01374', 'patient01386', 'patient01400', 'patient01412', 'patient01422', 'patient01446', 'patient01447', 'patient01457', 'patient01474', 'patient01475', 'patient01509', 'patient01510', 'patient01542', 'patient01549', 'patient01555', 'patient01557', 'patient01559', 'patient01608', 'patient01624', 'patient01626', 'patient01634', 'patient01669', 'patient01684', 'patient01694', 'patient01752', 'patient01773', 'patient01777', 'patient01780', 'patient01806', 'patient01810', 'patient01830', 'patient01839', 'patient01842', 'patient01856', 'patient01896', 'patient01917', 'patient01921', 'patient01972', 'patient01979', 'patient02013', 'patient02045', 'patient02052', 'patient02083', 'patient02141', 'patient02146', 'patient02175', 'patient02184', 'patient02188', 'patient02208', 'patient02252', 'patient02260', 'patient02265', 'patient02278', 'patient02303', 'patient02316', 'patient02383', 'patient02384', 'patient02411', 'patient02446', 'patient02448', 'patient02475', 'patient02517', 'patient02554', 'patient02565', 'patient02582', 'patient02583', 'patient02611', 'patient02614', 'patient02620', 'patient02626', 'patient02667', 'patient02695', 'patient02706', 'patient02762', 'patient02763', 'patient02805', 'patient02851', 'patient02880', 'patient02881', 'patient02903', 'patient02917', 'patient02931', 'patient02932', 'patient02946', 'patient02974', 'patient03021', 'patient03063', 'patient03077', 'patient03092', 'patient03096', 'patient03107', 'patient03144', 'patient03154', 'patient03166', 'patient03193', 'patient03240', 'patient03260', 'patient03262', 'patient03269', 'patient03310', 'patient03369', 'patient03395', 'patient03409', 'patient03453', 'patient03454', 'patient03458', 'patient03475', 'patient03492', 'patient03520', 'patient03543', 'patient03549', 'patient03551', 'patient03557', 'patient03567', 'patient03576', 'patient03592', 'patient03596', 'patient03609', 'patient03622', 'patient03629', 'patient03633', 'patient03639', 'patient03663', 'patient03666', 'patient03672', 'patient03745', 'patient03756', 'patient03765', 'patient03767', 'patient03799', 'patient03801', 'patient03828', 'patient03835', 'patient03844', 'patient03904', 'patient03913', 'patient03964', 'patient03970', 'patient04003', 'patient04009', 'patient04023', 'patient04040', 'patient04082', 'patient04084', 'patient04107', 'patient04109', 'patient04110', 'patient04119', 'patient04134', 'patient04156', 'patient04159', 'patient04174', 'patient04175', 'patient04179', 'patient04195', 'patient04205', 'patient04236', 'patient04244', 'patient04282', 'patient04313', 'patient04334', 'patient04350', 'patient04352', 'patient04357', 'patient04363', 'patient04417', 'patient04470', 'patient04569', 'patient04570', 'patient04579', 'patient04606', 'patient04633', 'patient04635', 'patient04641', 'patient04669', 'patient04748', 'patient04768', 'patient04779', 'patient04797', 'patient04838', 'patient04839', 'patient04849', 'patient04856', 'patient04884', 'patient04903', 'patient04904', 'patient04905', 'patient04906', 'patient04907', 'patient04908', 'patient04909', 'patient04910', 'patient04911', 'patient04912', 'patient04913', 'patient04914', 'patient04915', 'patient04916', 'patient04917', 'patient04918', 'patient04919', 'patient04920', 'patient04921', 'patient04922', 'patient04923', 'patient04924', 'patient04925', 'patient04926', 'patient04927', 'patient04928', 'patient04929', 'patient04930', 'patient04931', 'patient04932', 'patient04933', 'patient04934', 'patient04935', 'patient04936', 'patient04937', 'patient04938', 'patient04939', 'patient04940', 'patient04941', 'patient04942', 'patient04943', 'patient04944', 'patient04945', 'patient04946', 'patient04947', 'patient04948', 'patient04949', 'patient04950', 'patient04951', 'patient04952', 'patient04953', 'patient04954', 'patient04955', 'patient04956', 'patient04957', 'patient04958', 'patient04959', 'patient04960', 'patient04961', 'patient04962', 'patient04963', 'patient04964', 'patient04965', 'patient04966', 'patient04967', 'patient04968', 'patient04969', 'patient04970', 'patient04971', 'patient04972', 'patient04973', 'patient04974', 'patient04975', 'patient04976', 'patient04977', 'patient04978', 'patient04979', 'patient04980', 'patient04981', 'patient04982', 'patient04983', 'patient04984', 'patient04985', 'patient04986', 'patient04987', 'patient04988', 'patient04989', 'patient04990', 'patient04991', 'patient04992', 'patient04993', 'patient04994', 'patient04995', 'patient04996', 'patient04997', 'patient04998', 'patient04999', 'patient05000', 'patient05001', 'patient05002', 'patient05003', 'patient05004', 'patient05005', 'patient05006', 'patient05007', 'patient05008', 'patient05009', 'patient05010', 'patient05011', 'patient05012', 'patient05013', 'patient05014', 'patient05015', 'patient05016', 'patient05017', 'patient05018', 'patient05019', 'patient05020', 'patient05021', 'patient05022', 'patient05023', 'patient05024', 'patient05025', 'patient05026', 'patient05027', 'patient05028', 'patient05029', 'patient05030', 'patient05031', 'patient05032', 'patient05033', 'patient05034', 'patient05035', 'patient05036', 'patient05037', 'patient05038', 'patient05039', 'patient05040', 'patient05041', 'patient05042', 'patient05043', 'patient05044', 'patient05045', 'patient05046', 'patient05047', 'patient05048', 'patient05049', 'patient05050', 'patient05051', 'patient05052', 'patient05053', 'patient05054', 'patient05055', 'patient05056', 'patient05057', 'patient05058', 'patient05059', 'patient05060', 'patient05061', 'patient05062', 'patient05063', 'patient05064', 'patient05065', 'patient05066', 'patient05067', 'patient05068', 'patient05069', 'patient05070', 'patient05071', 'patient05072', 'patient05073', 'patient05074', 'patient05075', 'patient05076', 'patient05077', 'patient05078', 'patient05079', 'patient05080', 'patient05081', 'patient05082', 'patient05083', 'patient05084', 'patient05085', 'patient05086', 'patient05087', 'patient05088', 'patient05089', 'patient05090', 'patient05091', 'patient05092', 'patient05093', 'patient05094', 'patient05095', 'patient05096', 'patient05097', 'patient05098', 'patient05099', 'patient05100', 'patient05101', 'patient05102', 'patient05103', 'patient05104', 'patient05105', 'patient05106', 'patient05107', 'patient05108', 'patient05109', 'patient05110', 'patient05111', 'patient05112', 'patient05113', 'patient05114', 'patient05115', 'patient05116', 'patient05117', 'patient05118', 'patient05119', 'patient05120', 'patient05121', 'patient05122', 'patient05123', 'patient05124', 'patient05125', 'patient05126', 'patient05127', 'patient05128', 'patient05129', 'patient05130', 'patient05131', 'patient05132', 'patient05133', 'patient05134', 'patient05135', 'patient05136', 'patient05137', 'patient05138', 'patient05139', 'patient05140', 'patient05141', 'patient05142', 'patient05143', 'patient05144', 'patient05145', 'patient05146', 'patient05147', 'patient05148', 'patient05149', 'patient05150', 'patient05151', 'patient05152', 'patient05153', 'patient05154', 'patient05155', 'patient05156', 'patient05157', 'patient05158', 'patient05159', 'patient05160', 'patient05161', 'patient05162', 'patient05163', 'patient05164', 'patient05165', 'patient05166', 'patient05167', 'patient05168', 'patient05169', 'patient05170', 'patient05171', 'patient05172', 'patient05173', 'patient05174', 'patient05175', 'patient05176', 'patient05177', 'patient05178', 'patient05179', 'patient05180', 'patient05181', 'patient05182', 'patient05183', 'patient05184', 'patient05185', 'patient05186', 'patient05187', 'patient05188', 'patient05189', 'patient05190', 'patient05191', 'patient05192', 'patient05193', 'patient05194', 'patient05195', 'patient05196', 'patient05197', 'patient05198', 'patient05199', 'patient05200', 'patient05201', 'patient05202', 'patient05203', 'patient05204', 'patient05205', 'patient05206', 'patient05207', 'patient05208', 'patient05209', 'patient05210', 'patient05211', 'patient05212', 'patient05213', 'patient05214', 'patient05215', 'patient05216', 'patient05217', 'patient05218', 'patient05219', 'patient05220', 'patient05221', 'patient05222', 'patient05223', 'patient05224', 'patient05225', 'patient05226', 'patient05227', 'patient05228', 'patient05229', 'patient05230', 'patient05231', 'patient05232', 'patient05233', 'patient05234', 'patient05235', 'patient05236', 'patient05237', 'patient05238', 'patient05239', 'patient05240', 'patient05241', 'patient05242', 'patient05243', 'patient05244', 'patient05245', 'patient05246', 'patient05247', 'patient05248', 'patient05249', 'patient05250', 'patient05251', 'patient05252', 'patient05253', 'patient05254', 'patient05255', 'patient05256', 'patient05257', 'patient05258', 'patient05259', 'patient05260', 'patient05261', 'patient05262', 'patient05263', 'patient05264', 'patient05265', 'patient05266', 'patient05267', 'patient05268', 'patient05269', 'patient05270', 'patient05271', 'patient05272', 'patient05273', 'patient05274', 'patient05275', 'patient05276', 'patient05277', 'patient05278', 'patient05279', 'patient05280', 'patient05281', 'patient05282', 'patient05283', 'patient05284', 'patient05285', 'patient05286', 'patient05287', 'patient05288', 'patient05289', 'patient05290', 'patient05291', 'patient05292', 'patient05293', 'patient05294', 'patient05295', 'patient05296', 'patient05297', 'patient05298', 'patient05299', 'patient05300', 'patient05301', 'patient05302', 'patient05303', 'patient05304', 'patient05305', 'patient05306', 'patient05307', 'patient05308', 'patient05309', 'patient05310', 'patient05311', 'patient05312', 'patient05313', 'patient05314', 'patient05315', 'patient05316', 'patient05317', 'patient05318', 'patient05319', 'patient05320', 'patient05321', 'patient05322', 'patient05323', 'patient05324', 'patient05325', 'patient05326', 'patient05327', 'patient05328', 'patient05329', 'patient05330', 'patient05331', 'patient05332', 'patient05333', 'patient05334', 'patient05335', 'patient05336', 'patient05337', 'patient05338', 'patient05339', 'patient05340', 'patient05341', 'patient05342', 'patient05343', 'patient05344', 'patient05345', 'patient05346', 'patient05347', 'patient05348', 'patient05349', 'patient05350', 'patient05351', 'patient05352', 'patient05353', 'patient05354', 'patient05355', 'patient05356', 'patient05357', 'patient05358', 'patient05359', 'patient05360', 'patient05361', 'patient05362', 'patient05363', 'patient05364', 'patient05365', 'patient05366', 'patient05367', 'patient05368', 'patient05369', 'patient05370', 'patient05371', 'patient05372', 'patient05373', 'patient05374', 'patient05375', 'patient05376', 'patient05377', 'patient05378', 'patient05379', 'patient05380', 'patient05381', 'patient05382', 'patient05383', 'patient05384', 'patient05385', 'patient05386', 'patient05387', 'patient05388', 'patient05389', 'patient05390', 'patient05391', 'patient05392', 'patient05393', 'patient05394', 'patient05395', 'patient05396', 'patient05397', 'patient05398', 'patient05399', 'patient05400', 'patient05401', 'patient05402', 'patient05403', 'patient05404', 'patient05405', 'patient05406', 'patient05407', 'patient05408', 'patient05409', 'patient05410', 'patient05411', 'patient05412', 'patient05413', 'patient05414', 'patient05415', 'patient05416', 'patient05417', 'patient05418', 'patient05419', 'patient05420', 'patient05421', 'patient05422', 'patient05423', 'patient05424', 'patient05425', 'patient05426', 'patient05427', 'patient05428', 'patient05429', 'patient05430', 'patient05431', 'patient05432', 'patient05433', 'patient05434', 'patient05435', 'patient05436', 'patient05437', 'patient05438', 'patient05439', 'patient05440', 'patient05441', 'patient05442', 'patient05443', 'patient05444', 'patient05445', 'patient05446', 'patient05447', 'patient05448', 'patient05449', 'patient05450', 'patient05451', 'patient05452', 'patient05453', 'patient05454', 'patient05455', 'patient05456', 'patient05457', 'patient05458', 'patient05459', 'patient05460', 'patient05461', 'patient05462', 'patient05463', 'patient05464', 'patient05465', 'patient05466', 'patient05467', 'patient05468', 'patient05469', 'patient05470', 'patient05471', 'patient05472', 'patient05473', 'patient05474', 'patient05475', 'patient05476', 'patient05477', 'patient05478', 'patient05479', 'patient05480', 'patient05481', 'patient05482', 'patient05483', 'patient05484', 'patient05485', 'patient05486', 'patient05487', 'patient05488', 'patient05489', 'patient05490', 'patient05491', 'patient05492', 'patient05493', 'patient05494', 'patient05495', 'patient05496', 'patient05497', 'patient05498', 'patient05499', 'patient05500', 'patient05501', 'patient05502', 'patient05503', 'patient05504', 'patient05505', 'patient05506', 'patient05507', 'patient05508', 'patient05509', 'patient05510', 'patient05511', 'patient05512', 'patient05513', 'patient05514', 'patient05515', 'patient05516', 'patient05517', 'patient05518', 'patient05519', 'patient05520', 'patient05521', 'patient05522', 'patient05523', 'patient05524', 'patient05525', 'patient05526', 'patient05527', 'patient05528', 'patient05529', 'patient05530', 'patient05531', 'patient05532', 'patient05533', 'patient05534', 'patient05535', 'patient05536', 'patient05537', 'patient05538', 'patient05539', 'patient05540', 'patient05541', 'patient05542', 'patient05543', 'patient05544', 'patient05545', 'patient05546', 'patient05547', 'patient05548', 'patient05549', 'patient05550', 'patient05551', 'patient05552', 'patient05553', 'patient05554', 'patient05555', 'patient05556', 'patient05557', 'patient05558', 'patient05559', 'patient05560', 'patient05561', 'patient05562', 'patient05563', 'patient05564', 'patient05565', 'patient05566', 'patient05567', 'patient05568', 'patient05569', 'patient05570', 'patient05571', 'patient05572', 'patient05573', 'patient05574', 'patient05575', 'patient05576', 'patient05577', 'patient05578', 'patient05579', 'patient05580', 'patient05581', 'patient05582', 'patient05583', 'patient05584', 'patient05585', 'patient05586', 'patient05587', 'patient05588', 'patient05589', 'patient05590', 'patient05591', 'patient05592', 'patient05593', 'patient05594', 'patient05595', 'patient05596', 'patient05597', 'patient05598', 'patient05599', 'patient05600', 'patient05601', 'patient05602', 'patient05603', 'patient05604', 'patient05605', 'patient05606', 'patient05607', 'patient05608', 'patient05609', 'patient05610', 'patient05611', 'patient05612', 'patient05613', 'patient05614', 'patient05615', 'patient05616', 'patient05617', 'patient05618', 'patient05619', 'patient05620', 'patient05621', 'patient05622', 'patient05623', 'patient05624', 'patient05625', 'patient05626', 'patient05627', 'patient05628', 'patient05629', 'patient05630', 'patient05631', 'patient05632', 'patient05633', 'patient05634', 'patient05635', 'patient05636', 'patient05637', 'patient05638', 'patient05639', 'patient05640', 'patient05641', 'patient05642', 'patient05643', 'patient05644', 'patient05645', 'patient05646', 'patient05647', 'patient05648', 'patient05649', 'patient05650', 'patient05651', 'patient05652', 'patient05653', 'patient05654', 'patient05655', 'patient05656', 'patient05657', 'patient05658', 'patient05659', 'patient05660', 'patient05661', 'patient05662', 'patient05663', 'patient05664', 'patient05665', 'patient05666', 'patient05667', 'patient05668', 'patient05669', 'patient05670', 'patient05671', 'patient05672', 'patient05673', 'patient05674', 'patient05675', 'patient05676', 'patient05677', 'patient05678', 'patient05679', 'patient05680', 'patient05681', 'patient05682', 'patient05683', 'patient05684', 'patient05685', 'patient05686', 'patient05687', 'patient05688', 'patient05689', 'patient05690', 'patient05691', 'patient05692', 'patient05693', 'patient05694', 'patient05695', 'patient05696', 'patient05697', 'patient05698', 'patient05699', 'patient05700', 'patient05701', 'patient05702', 'patient05703', 'patient05704', 'patient05705', 'patient05706', 'patient05707', 'patient05708', 'patient05709', 'patient05710', 'patient05711', 'patient05712', 'patient05713', 'patient05714', 'patient05715', 'patient05716', 'patient05717', 'patient05718', 'patient05719', 'patient05720', 'patient05721', 'patient05722', 'patient05723', 'patient05724', 'patient05725', 'patient05726', 'patient05727', 'patient05728', 'patient05729', 'patient05730', 'patient05731', 'patient05732', 'patient05733', 'patient05734', 'patient05735', 'patient05736', 'patient05737', 'patient05738', 'patient05739', 'patient05740', 'patient05741', 'patient05742', 'patient05743', 'patient05744', 'patient05745', 'patient05746', 'patient05747', 'patient05748', 'patient05749', 'patient05750', 'patient05751', 'patient05752', 'patient05753', 'patient05754', 'patient05755', 'patient05756', 'patient05757', 'patient05758', 'patient05759', 'patient05760', 'patient05761', 'patient05762', 'patient05763', 'patient05764', 'patient05765', 'patient05766', 'patient05767', 'patient05768', 'patient05769', 'patient05770', 'patient05771', 'patient05772', 'patient05773', 'patient05774', 'patient05775', 'patient05776', 'patient05777', 'patient05778', 'patient05779', 'patient05780', 'patient05781', 'patient05782', 'patient05783', 'patient05784', 'patient05785', 'patient05786', 'patient05787', 'patient05788', 'patient05789', 'patient05790', 'patient05791', 'patient05792', 'patient05793', 'patient05794', 'patient05795', 'patient05796', 'patient05797', 'patient05798', 'patient05799', 'patient05800', 'patient05801', 'patient05802', 'patient05803', 'patient05804', 'patient05805', 'patient05806', 'patient05807', 'patient05808', 'patient05809', 'patient05810', 'patient05811', 'patient05812', 'patient05813', 'patient05814', 'patient05815', 'patient05816', 'patient05817', 'patient05818', 'patient05819', 'patient05820', 'patient05821', 'patient05822', 'patient05823', 'patient05824', 'patient05825', 'patient05826', 'patient05827', 'patient05828', 'patient05829', 'patient05830', 'patient05831', 'patient05832', 'patient05833', 'patient05834', 'patient05835', 'patient05836', 'patient05837', 'patient05838', 'patient05839', 'patient05840', 'patient05841', 'patient05842', 'patient05843', 'patient05844', 'patient05845', 'patient05846', 'patient05847', 'patient05848', 'patient05849', 'patient05850', 'patient05851', 'patient05852', 'patient05853', 'patient05854', 'patient05855', 'patient05856', 'patient05857', 'patient05858', 'patient05859', 'patient05860', 'patient05861', 'patient05862', 'patient05863', 'patient05864', 'patient05865', 'patient05866', 'patient05867', 'patient05868', 'patient05869', 'patient05870', 'patient05871', 'patient05872', 'patient05873', 'patient05874', 'patient05875', 'patient05876', 'patient05877', 'patient05878', 'patient05879', 'patient05880', 'patient05881', 'patient05882', 'patient05883', 'patient05884', 'patient05885', 'patient05886', 'patient05887', 'patient05888', 'patient05889', 'patient05890', 'patient05891', 'patient05892', 'patient05893', 'patient05894', 'patient05895', 'patient05896', 'patient05897', 'patient05898', 'patient05899', 'patient05900', 'patient05901', 'patient05902', 'patient05903', 'patient05904', 'patient05905', 'patient05906', 'patient05907', 'patient05908', 'patient05909', 'patient05910', 'patient05911', 'patient05912', 'patient05913', 'patient05914', 'patient05915', 'patient05916', 'patient05917', 'patient05918', 'patient05919', 'patient05920', 'patient05921', 'patient05922', 'patient05923', 'patient05924', 'patient05925', 'patient05926', 'patient05927', 'patient05928', 'patient05929', 'patient05930', 'patient05931', 'patient05932', 'patient05933', 'patient05934', 'patient05935', 'patient05936', 'patient05937', 'patient05938', 'patient05939', 'patient05940', 'patient05941', 'patient05942', 'patient05943', 'patient05944', 'patient05945', 'patient05946', 'patient05947', 'patient05948', 'patient05949', 'patient05950', 'patient05951', 'patient05952', 'patient05953', 'patient05954', 'patient05955', 'patient05956', 'patient05957', 'patient05958', 'patient05959', 'patient05960', 'patient05961', 'patient05962', 'patient05963', 'patient05964', 'patient05965', 'patient05966', 'patient05967', 'patient05968', 'patient05969', 'patient05970', 'patient05971', 'patient05972', 'patient05973', 'patient05974', 'patient05975', 'patient05976', 'patient05977', 'patient05978', 'patient05979', 'patient05980', 'patient05981', 'patient05982', 'patient05983', 'patient05984', 'patient05985', 'patient05986', 'patient05987', 'patient05988', 'patient05989', 'patient05990', 'patient05991', 'patient05992', 'patient05993', 'patient05994', 'patient05995', 'patient05996', 'patient05997', 'patient05998', 'patient05999', 'patient06000', 'patient06001', 'patient06002', 'patient06003', 'patient06004', 'patient06005', 'patient06006', 'patient06007', 'patient06008', 'patient06009', 'patient06010', 'patient06011', 'patient06012', 'patient06013', 'patient06014', 'patient06015', 'patient06016', 'patient06017', 'patient06018', 'patient06019', 'patient06020', 'patient06021', 'patient06022', 'patient06023', 'patient06024', 'patient06025', 'patient06026', 'patient06027', 'patient06028', 'patient06029', 'patient06030', 'patient06031', 'patient06032', 'patient06033', 'patient06034', 'patient06035', 'patient06036', 'patient06037', 'patient06038', 'patient06039', 'patient06040', 'patient06041', 'patient06042', 'patient06043', 'patient06044', 'patient06045', 'patient06046', 'patient06047', 'patient06048', 'patient06049', 'patient06050', 'patient06051', 'patient06052', 'patient06053', 'patient06054', 'patient06055', 'patient06056', 'patient06057', 'patient06058', 'patient06059', 'patient06060', 'patient06061', 'patient06062', 'patient06063', 'patient06064', 'patient06065', 'patient06066', 'patient06067', 'patient06068', 'patient06069', 'patient06070', 'patient06071', 'patient06072', 'patient06073', 'patient06074', 'patient06075', 'patient06076', 'patient06077', 'patient06078', 'patient06079', 'patient06080', 'patient06081', 'patient06082', 'patient06083', 'patient06084', 'patient06085', 'patient06086', 'patient06087', 'patient06088', 'patient06089', 'patient06090', 'patient06091', 'patient06092', 'patient06093', 'patient06094', 'patient06095', 'patient06096', 'patient06097', 'patient06098', 'patient06099', 'patient06100', 'patient06101', 'patient06102', 'patient06103', 'patient06104', 'patient06105', 'patient06106', 'patient06107', 'patient06108', 'patient06109', 'patient06110', 'patient06111', 'patient06112', 'patient06113', 'patient06114', 'patient06115', 'patient06116', 'patient06117', 'patient06118', 'patient06119', 'patient06120', 'patient06121', 'patient06122', 'patient06123', 'patient06124', 'patient06125', 'patient06126', 'patient06127', 'patient06128', 'patient06129', 'patient06130', 'patient06131', 'patient06132', 'patient06133', 'patient06134', 'patient06135', 'patient06136', 'patient06137', 'patient06138', 'patient06139', 'patient06140', 'patient06141', 'patient06142', 'patient06143', 'patient06144', 'patient06145', 'patient06146', 'patient06147', 'patient06148', 'patient06149', 'patient06150', 'patient06151', 'patient06152', 'patient06153', 'patient06154', 'patient06155', 'patient06156', 'patient06157', 'patient06158', 'patient06159', 'patient06160', 'patient06161', 'patient06162', 'patient06163', 'patient06164', 'patient06165', 'patient06166', 'patient06167', 'patient06168', 'patient06169', 'patient06170', 'patient06171', 'patient06172', 'patient06173', 'patient06174', 'patient06175', 'patient06176', 'patient06177', 'patient06178', 'patient06179', 'patient06180', 'patient06181', 'patient06182', 'patient06183', 'patient06184', 'patient06185', 'patient06186', 'patient06187', 'patient06188', 'patient06189', 'patient06190', 'patient06191', 'patient06192', 'patient06193', 'patient06194', 'patient06195', 'patient06196', 'patient06197', 'patient06198', 'patient06199', 'patient06200', 'patient06201', 'patient06202', 'patient06203', 'patient06204', 'patient06205', 'patient06206', 'patient06207', 'patient06208', 'patient06209', 'patient06210', 'patient06211', 'patient06212', 'patient06213', 'patient06214', 'patient06215', 'patient06216', 'patient06217', 'patient06218', 'patient06219', 'patient06220', 'patient06221', 'patient06222', 'patient06223', 'patient06224', 'patient06225', 'patient06226', 'patient06227', 'patient06228', 'patient06229', 'patient06230', 'patient06231', 'patient06232', 'patient06233', 'patient06234', 'patient06235', 'patient06236', 'patient06237', 'patient06238', 'patient06239', 'patient06240', 'patient06241', 'patient06242', 'patient06243', 'patient06244', 'patient06245', 'patient06246', 'patient06247', 'patient06248', 'patient06249', 'patient06250', 'patient06251', 'patient06252', 'patient06253', 'patient06254', 'patient06255', 'patient06256', 'patient06257', 'patient06258', 'patient06259', 'patient06260', 'patient06261', 'patient06262', 'patient06263', 'patient06264', 'patient06265', 'patient06266', 'patient06267', 'patient06268', 'patient06269', 'patient06270', 'patient06271', 'patient06272', 'patient06273', 'patient06274', 'patient06275', 'patient06276', 'patient06277', 'patient06278', 'patient06279', 'patient06280', 'patient06281', 'patient06282', 'patient06283', 'patient06284', 'patient06285', 'patient06286', 'patient06287', 'patient06288', 'patient06289', 'patient06290', 'patient06291', 'patient06292', 'patient06293', 'patient06294', 'patient06295', 'patient06296', 'patient06297', 'patient06298', 'patient06299', 'patient06300', 'patient06301', 'patient06302', 'patient06303', 'patient06304', 'patient06305', 'patient06306', 'patient06307', 'patient06308', 'patient06309', 'patient06310', 'patient06311', 'patient06312', 'patient06313', 'patient06314', 'patient06315', 'patient06316', 'patient06317', 'patient06318', 'patient06319', 'patient06320', 'patient06321', 'patient06322', 'patient06323', 'patient06324', 'patient06325', 'patient06326', 'patient06327', 'patient06328', 'patient06329', 'patient06330', 'patient06331', 'patient06332', 'patient06333', 'patient06334', 'patient06335', 'patient06336', 'patient06337', 'patient06338', 'patient06339', 'patient06340', 'patient06341', 'patient06342', 'patient06343', 'patient06344', 'patient06345', 'patient06346', 'patient06347', 'patient06348', 'patient06349', 'patient06350', 'patient06351', 'patient06352', 'patient06353', 'patient06354', 'patient06355', 'patient06356', 'patient06357', 'patient06358']\n"
     ]
    }
   ],
   "source": [
    "print(\"IMG_DIR:\", IMG_DIR)\n",
    "print(\"Folders inside:\", os.listdir(IMG_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1776b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36808 images\n"
     ]
    }
   ],
   "source": [
    "# Your dataset root\n",
    "IMG_DIR = \"C:/College/Projects/X-RayComparison/Data/train\"\n",
    "\n",
    "# Your transform\n",
    "transform = T.Compose([\n",
    "    T.Resize((128, 128)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "dataset = MURAXrayDataset(IMG_DIR, transform=transform)\n",
    "print(f\"Found {len(dataset)} images\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_channels=1, features_g=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            # Input: N x z_dim x 1 x 1\n",
    "            nn.ConvTranspose2d(z_dim, features_g * 8, kernel_size=4, stride=1, padding=0),  # 4x4\n",
    "            nn.BatchNorm2d(features_g * 8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g * 8, features_g * 4, kernel_size=4, stride=2, padding=1),  # 8x8\n",
    "            nn.BatchNorm2d(features_g * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g * 4, features_g * 2, kernel_size=4, stride=2, padding=1),  # 16x16\n",
    "            nn.BatchNorm2d(features_g * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g * 2, features_g, kernel_size=4, stride=2, padding=1),  # 32x32\n",
    "            nn.BatchNorm2d(features_g),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g, img_channels, kernel_size=4, stride=2, padding=1),  # 64x64\n",
    "            nn.Tanh()  # Output in range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d48759",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels=1, features_d=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            # Input: N x 1 x 64 x 64\n",
    "            nn.Conv2d(img_channels, features_d, kernel_size=4, stride=2, padding=1),  # 32x32\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(features_d, features_d * 2, kernel_size=4, stride=2, padding=1),  # 16x16\n",
    "            nn.BatchNorm2d(features_d * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(features_d * 2, features_d * 4, kernel_size=4, stride=2, padding=1),  # 8x8\n",
    "            nn.BatchNorm2d(features_d * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(features_d * 4, features_d * 8, kernel_size=4, stride=2, padding=1),  # 4x4\n",
    "            nn.BatchNorm2d(features_d * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=1, padding=0),  # 1x1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x).view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f2f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# Hyperparameters\n",
    "z_dim = 100\n",
    "lr = 2e-6\n",
    "beta1 = 0.5\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "gen = Generator(z_dim).to(device)\n",
    "disc = Discriminator().to(device)\n",
    "gen.apply(weights_init)\n",
    "disc.apply(weights_init)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta1, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8997d267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\apps\\work\\conda\\envs\\gan-xray\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1205352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]: 100%|██████████| 576/576 [01:42<00:00,  5.62it/s, lossD=5.66e-8, lossG=19.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] Loss D: 0.0000, Loss G: 19.9475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/100]: 100%|██████████| 576/576 [01:49<00:00,  5.27it/s, lossD=6.39e-7, lossG=16.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100] Loss D: 0.0000, Loss G: 16.0763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/100]: 100%|██████████| 576/576 [01:49<00:00,  5.27it/s, lossD=7.16e-8, lossG=17.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100] Loss D: 0.0000, Loss G: 17.4725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/100]: 100%|██████████| 576/576 [01:48<00:00,  5.28it/s, lossD=4.14e-8, lossG=17.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100] Loss D: 0.0000, Loss G: 17.8013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/100]: 100%|██████████| 576/576 [01:46<00:00,  5.43it/s, lossD=1.94e-7, lossG=17.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100] Loss D: 0.0000, Loss G: 17.7003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/100]: 100%|██████████| 576/576 [01:45<00:00,  5.44it/s, lossD=5.71e-8, lossG=19.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100] Loss D: 0.0000, Loss G: 19.1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/100]: 100%|██████████| 576/576 [01:46<00:00,  5.40it/s, lossD=1.63e-8, lossG=19.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100] Loss D: 0.0000, Loss G: 19.3763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/100]: 100%|██████████| 576/576 [01:46<00:00,  5.42it/s, lossD=2.59e-8, lossG=19.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100] Loss D: 0.0000, Loss G: 19.2901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/100]: 100%|██████████| 576/576 [01:45<00:00,  5.44it/s, lossD=1.66e-8, lossG=20.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100] Loss D: 0.0000, Loss G: 20.2571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/100]: 100%|██████████| 576/576 [01:46<00:00,  5.39it/s, lossD=1.89e-5, lossG=14.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100] Loss D: 0.0000, Loss G: 14.3179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/100]: 100%|██████████| 576/576 [01:46<00:00,  5.39it/s, lossD=7.36e-7, lossG=16.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100] Loss D: 0.0000, Loss G: 16.1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/100]: 100%|██████████| 576/576 [01:45<00:00,  5.44it/s, lossD=2.69e-6, lossG=18.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100] Loss D: 0.0000, Loss G: 18.6366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/100]: 100%|██████████| 576/576 [01:47<00:00,  5.34it/s, lossD=7.01e-7, lossG=15.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100] Loss D: 0.0000, Loss G: 15.1290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/100]: 100%|██████████| 576/576 [01:46<00:00,  5.39it/s, lossD=2.31e-6, lossG=15.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100] Loss D: 0.0000, Loss G: 15.9403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/100]: 100%|██████████| 576/576 [01:49<00:00,  5.27it/s, lossD=1.16e-5, lossG=17.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100] Loss D: 0.0000, Loss G: 17.6142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/100]: 100%|██████████| 576/576 [02:18<00:00,  4.15it/s, lossD=6.89e-6, lossG=18]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100] Loss D: 0.0000, Loss G: 17.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/100]: 100%|██████████| 576/576 [02:30<00:00,  3.82it/s, lossD=2.87e-7, lossG=18]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100] Loss D: 0.0000, Loss G: 17.9756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/100]: 100%|██████████| 576/576 [01:51<00:00,  5.15it/s, lossD=8.14e-8, lossG=33.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100] Loss D: 0.0000, Loss G: 33.7162\n",
      "Warning: Generator struggling for 5+ epochs. Consider lowering LR or adjusting model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/100]: 100%|██████████| 576/576 [02:00<00:00,  4.79it/s, lossD=3.25e-8, lossG=26.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100] Loss D: 0.0000, Loss G: 26.5854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/100]: 100%|██████████| 576/576 [01:59<00:00,  4.81it/s, lossD=5.12e-8, lossG=20.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100] Loss D: 0.0000, Loss G: 20.2486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/100]: 100%|██████████| 576/576 [01:51<00:00,  5.19it/s, lossD=8.84e-8, lossG=18.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100] Loss D: 0.0000, Loss G: 18.3620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/100]: 100%|██████████| 576/576 [01:49<00:00,  5.25it/s, lossD=8.54e-7, lossG=19.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100] Loss D: 0.0000, Loss G: 19.2710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/100]: 100%|██████████| 576/576 [03:00<00:00,  3.18it/s, lossD=1.17e-6, lossG=14.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100] Loss D: 0.0000, Loss G: 14.1553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/100]: 100%|██████████| 576/576 [02:13<00:00,  4.31it/s, lossD=8.22e-8, lossG=17.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100] Loss D: 0.0000, Loss G: 17.5308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/100]: 100%|██████████| 576/576 [01:49<00:00,  5.27it/s, lossD=6.11e-7, lossG=16.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100] Loss D: 0.0000, Loss G: 16.6688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/100]: 100%|██████████| 576/576 [01:45<00:00,  5.45it/s, lossD=5.45e-7, lossG=17.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100] Loss D: 0.0000, Loss G: 17.4085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/100]: 100%|██████████| 576/576 [01:41<00:00,  5.66it/s, lossD=1.45e-7, lossG=16.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100] Loss D: 0.0000, Loss G: 16.3968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28/100]: 100%|██████████| 576/576 [01:46<00:00,  5.40it/s, lossD=7.47e-7, lossG=17.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100] Loss D: 0.0000, Loss G: 17.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/100]: 100%|██████████| 576/576 [01:47<00:00,  5.36it/s, lossD=2.06e-7, lossG=17.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100] Loss D: 0.0000, Loss G: 17.4388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30/100]: 100%|██████████| 576/576 [01:47<00:00,  5.36it/s, lossD=1.81e-8, lossG=19.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100] Loss D: 0.0000, Loss G: 19.8456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [31/100]: 100%|██████████| 576/576 [01:47<00:00,  5.34it/s, lossD=2.53e-8, lossG=21.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100] Loss D: 0.0000, Loss G: 21.2260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [32/100]: 100%|██████████| 576/576 [01:47<00:00,  5.36it/s, lossD=1.88e-8, lossG=29.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100] Loss D: 0.0000, Loss G: 29.9227\n",
      "Warning: Generator struggling for 5+ epochs. Consider lowering LR or adjusting model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [33/100]: 100%|██████████| 576/576 [01:47<00:00,  5.36it/s, lossD=7.45e-9, lossG=30.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100] Loss D: 0.0000, Loss G: 30.0795\n",
      "Warning: Generator struggling for 5+ epochs. Consider lowering LR or adjusting model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [34/100]: 100%|██████████| 576/576 [01:46<00:00,  5.39it/s, lossD=5.96e-9, lossG=35.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100] Loss D: 0.0000, Loss G: 35.6226\n",
      "Warning: Generator struggling for 5+ epochs. Consider lowering LR or adjusting model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [35/100]: 100%|██████████| 576/576 [01:47<00:00,  5.35it/s, lossD=1.1e-8, lossG=28.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100] Loss D: 0.0000, Loss G: 28.8635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [36/100]: 100%|██████████| 576/576 [01:47<00:00,  5.35it/s, lossD=2.02e-13, lossG=29.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100] Loss D: 0.0000, Loss G: 29.1030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [37/100]: 100%|██████████| 576/576 [01:47<00:00,  5.35it/s, lossD=2.98e-10, lossG=30.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100] Loss D: 0.0000, Loss G: 30.3295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [38/100]: 100%|██████████| 576/576 [01:46<00:00,  5.42it/s, lossD=8.94e-10, lossG=31.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100] Loss D: 0.0000, Loss G: 31.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [39/100]: 100%|██████████| 576/576 [01:49<00:00,  5.26it/s, lossD=9.45e-14, lossG=30.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100] Loss D: 0.0000, Loss G: 30.8428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [40/100]: 100%|██████████| 576/576 [01:49<00:00,  5.25it/s, lossD=5.96e-10, lossG=30.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100] Loss D: 0.0000, Loss G: 30.5985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [41/100]: 100%|██████████| 576/576 [01:44<00:00,  5.53it/s, lossD=4.77e-9, lossG=30.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100] Loss D: 0.0000, Loss G: 30.1591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [42/100]: 100%|██████████| 576/576 [01:48<00:00,  5.31it/s, lossD=2.1e-9, lossG=25.4]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100] Loss D: 0.0000, Loss G: 25.3513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [43/100]: 100%|██████████| 576/576 [01:47<00:00,  5.34it/s, lossD=6.55e-9, lossG=23.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100] Loss D: 0.0000, Loss G: 23.1202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [44/100]: 100%|██████████| 576/576 [01:48<00:00,  5.32it/s, lossD=1.27e-7, lossG=21.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100] Loss D: 0.0000, Loss G: 21.2192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [45/100]: 100%|██████████| 576/576 [01:44<00:00,  5.50it/s, lossD=1.54e-9, lossG=22]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100] Loss D: 0.0000, Loss G: 22.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [46/100]: 100%|██████████| 576/576 [01:47<00:00,  5.38it/s, lossD=3.07e-9, lossG=21.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100] Loss D: 0.0000, Loss G: 21.5129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [47/100]: 100%|██████████| 576/576 [01:47<00:00,  5.37it/s, lossD=1.37e-9, lossG=21.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100] Loss D: 0.0000, Loss G: 21.7811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [48/100]: 100%|██████████| 576/576 [01:47<00:00,  5.36it/s, lossD=1.07e-9, lossG=22]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100] Loss D: 0.0000, Loss G: 22.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [49/100]: 100%|██████████| 576/576 [01:46<00:00,  5.40it/s, lossD=1.68e-10, lossG=22.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100] Loss D: 0.0000, Loss G: 22.0964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [50/100]: 100%|██████████| 576/576 [01:46<00:00,  5.38it/s, lossD=3.83e-10, lossG=22.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100] Loss D: 0.0000, Loss G: 22.6113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [51/100]: 100%|██████████| 576/576 [01:47<00:00,  5.37it/s, lossD=1.64e-9, lossG=22.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100] Loss D: 0.0000, Loss G: 22.9283\n",
      "Warning: Generator struggling for 5+ epochs. Consider lowering LR or adjusting model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [52/100]: 100%|██████████| 576/576 [01:47<00:00,  5.38it/s, lossD=8.26e-11, lossG=23]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100] Loss D: 0.0000, Loss G: 23.0327\n",
      "Warning: Generator struggling for 5+ epochs. Consider lowering LR or adjusting model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [53/100]: 100%|██████████| 576/576 [01:43<00:00,  5.55it/s, lossD=2.07e-8, lossG=23.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100] Loss D: 0.0000, Loss G: 23.4456\n",
      "Warning: Generator struggling for 5+ epochs. Consider lowering LR or adjusting model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [54/100]: 100%|██████████| 576/576 [01:45<00:00,  5.48it/s, lossD=3.84e-11, lossG=24]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100] Loss D: 0.0000, Loss G: 23.9772\n",
      "Warning: Generator struggling for 5+ epochs. Consider lowering LR or adjusting model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [55/100]: 100%|██████████| 576/576 [01:48<00:00,  5.33it/s, lossD=2.8e-11, lossG=24.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100] Loss D: 0.0000, Loss G: 24.6057\n",
      "Warning: Generator struggling for 5+ epochs. Consider lowering LR or adjusting model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [56/100]: 100%|██████████| 576/576 [03:23<00:00,  2.83it/s, lossD=1.52e-9, lossG=24.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100] Loss D: 0.0000, Loss G: 24.5853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [57/100]: 100%|██████████| 576/576 [02:10<00:00,  4.43it/s, lossD=2.71e-9, lossG=23.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100] Loss D: 0.0000, Loss G: 23.7047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [58/100]: 100%|██████████| 576/576 [01:52<00:00,  5.13it/s, lossD=1.5e-9, lossG=26.9]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100] Loss D: 0.0000, Loss G: 26.9082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [59/100]: 100%|██████████| 576/576 [01:51<00:00,  5.18it/s, lossD=1.94e-11, lossG=24.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100] Loss D: 0.0000, Loss G: 24.0826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [60/100]: 100%|██████████| 576/576 [01:58<00:00,  4.88it/s, lossD=3.01e-10, lossG=25.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100] Loss D: 0.0000, Loss G: 25.6272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [61/100]: 100%|██████████| 576/576 [02:15<00:00,  4.25it/s, lossD=1.67e-13, lossG=28.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100] Loss D: 0.0000, Loss G: 28.3950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [62/100]: 100%|██████████| 576/576 [02:11<00:00,  4.38it/s, lossD=3.81e-12, lossG=25.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100] Loss D: 0.0000, Loss G: 25.8975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [63/100]: 100%|██████████| 576/576 [02:07<00:00,  4.53it/s, lossD=7.18e-14, lossG=27.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100] Loss D: 0.0000, Loss G: 27.7831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [64/100]: 100%|██████████| 576/576 [02:08<00:00,  4.47it/s, lossD=8.94e-10, lossG=63.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100] Loss D: 0.0000, Loss G: 63.3743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [65/100]: 100%|██████████| 576/576 [02:06<00:00,  4.54it/s, lossD=6.71e-25, lossG=63.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100] Loss D: 0.0000, Loss G: 63.2651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [66/100]: 100%|██████████| 576/576 [02:03<00:00,  4.66it/s, lossD=5.39e-23, lossG=62]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100] Loss D: 0.0000, Loss G: 61.9620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [67/100]: 100%|██████████| 576/576 [01:50<00:00,  5.21it/s, lossD=9.42e-22, lossG=62.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100] Loss D: 0.0000, Loss G: 62.5387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [68/100]: 100%|██████████| 576/576 [02:04<00:00,  4.64it/s, lossD=3.89e-22, lossG=60.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100] Loss D: 0.0000, Loss G: 60.6926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [69/100]: 100%|██████████| 576/576 [01:52<00:00,  5.11it/s, lossD=2.92e-5, lossG=21.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100] Loss D: 0.0000, Loss G: 21.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [70/100]: 100%|██████████| 576/576 [02:20<00:00,  4.10it/s, lossD=1.55e-6, lossG=29.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100] Loss D: 0.0000, Loss G: 29.2866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [71/100]: 100%|██████████| 576/576 [02:49<00:00,  3.41it/s, lossD=2.68e-8, lossG=33.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100] Loss D: 0.0000, Loss G: 33.5942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [72/100]: 100%|██████████| 576/576 [02:05<00:00,  4.60it/s, lossD=1.04e-7, lossG=36.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100] Loss D: 0.0000, Loss G: 36.1563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [73/100]: 100%|██████████| 576/576 [01:54<00:00,  5.04it/s, lossD=1.23e-6, lossG=29.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100] Loss D: 0.0000, Loss G: 29.6398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [74/100]: 100%|██████████| 576/576 [01:52<00:00,  5.11it/s, lossD=3.57e-7, lossG=30.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100] Loss D: 0.0000, Loss G: 30.6642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [75/100]: 100%|██████████| 576/576 [01:50<00:00,  5.20it/s, lossD=1.65e-6, lossG=28]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100] Loss D: 0.0000, Loss G: 28.0303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [76/100]: 100%|██████████| 576/576 [01:53<00:00,  5.06it/s, lossD=1.45e-6, lossG=28.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100] Loss D: 0.0000, Loss G: 28.8147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [77/100]: 100%|██████████| 576/576 [01:49<00:00,  5.25it/s, lossD=5.37e-9, lossG=26.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100] Loss D: 0.0000, Loss G: 26.6773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [78/100]: 100%|██████████| 576/576 [01:50<00:00,  5.20it/s, lossD=4.17e-8, lossG=28.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100] Loss D: 0.0000, Loss G: 28.7117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [79/100]: 100%|██████████| 576/576 [01:48<00:00,  5.30it/s, lossD=1.19e-8, lossG=26.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100] Loss D: 0.0000, Loss G: 26.4826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [80/100]: 100%|██████████| 576/576 [01:48<00:00,  5.30it/s, lossD=6.59e-8, lossG=27.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100] Loss D: 0.0000, Loss G: 27.8917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [81/100]: 100%|██████████| 576/576 [01:44<00:00,  5.53it/s, lossD=2.71e-8, lossG=25.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100] Loss D: 0.0000, Loss G: 25.9058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [82/100]: 100%|██████████| 576/576 [01:43<00:00,  5.57it/s, lossD=6.32e-10, lossG=25.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100] Loss D: 0.0000, Loss G: 25.8540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [83/100]: 100%|██████████| 576/576 [01:43<00:00,  5.55it/s, lossD=2.76e-9, lossG=24.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100] Loss D: 0.0000, Loss G: 24.0788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [84/100]: 100%|██████████| 576/576 [01:42<00:00,  5.60it/s, lossD=9.27e-8, lossG=24]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100] Loss D: 0.0000, Loss G: 24.0397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [85/100]: 100%|██████████| 576/576 [01:59<00:00,  4.84it/s, lossD=3.81e-10, lossG=23] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100] Loss D: 0.0000, Loss G: 23.0307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [86/100]: 100%|██████████| 576/576 [02:14<00:00,  4.29it/s, lossD=9.12e-10, lossG=24.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100] Loss D: 0.0000, Loss G: 24.1842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [87/100]: 100%|██████████| 576/576 [01:54<00:00,  5.05it/s, lossD=1.57e-7, lossG=24.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100] Loss D: 0.0000, Loss G: 24.5350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [88/100]: 100%|██████████| 576/576 [01:53<00:00,  5.06it/s, lossD=6.11e-10, lossG=24.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100] Loss D: 0.0000, Loss G: 24.3712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [89/100]: 100%|██████████| 576/576 [01:55<00:00,  4.99it/s, lossD=5.19e-8, lossG=25.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100] Loss D: 0.0000, Loss G: 25.5484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [90/100]: 100%|██████████| 576/576 [01:56<00:00,  4.95it/s, lossD=5.49e-8, lossG=24.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100] Loss D: 0.0000, Loss G: 24.5380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [91/100]: 100%|██████████| 576/576 [01:56<00:00,  4.95it/s, lossD=3.88e-10, lossG=26.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100] Loss D: 0.0000, Loss G: 26.9023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [92/100]: 100%|██████████| 576/576 [01:56<00:00,  4.96it/s, lossD=1.58e-8, lossG=25.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100] Loss D: 0.0000, Loss G: 25.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [93/100]: 100%|██████████| 576/576 [01:56<00:00,  4.94it/s, lossD=3.33e-10, lossG=23.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100] Loss D: 0.0000, Loss G: 23.4686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [94/100]: 100%|██████████| 576/576 [01:56<00:00,  4.94it/s, lossD=3.96e-9, lossG=21.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100] Loss D: 0.0000, Loss G: 21.3644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [95/100]: 100%|██████████| 576/576 [01:55<00:00,  5.00it/s, lossD=9.85e-9, lossG=19.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100] Loss D: 0.0000, Loss G: 19.7571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [96/100]: 100%|██████████| 576/576 [01:55<00:00,  4.98it/s, lossD=2e-9, lossG=19.5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100] Loss D: 0.0000, Loss G: 19.5469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [97/100]: 100%|██████████| 576/576 [01:56<00:00,  4.95it/s, lossD=4.4e-9, lossG=20.2]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100] Loss D: 0.0000, Loss G: 20.2247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [98/100]: 100%|██████████| 576/576 [01:55<00:00,  4.98it/s, lossD=1.08e-9, lossG=21.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100] Loss D: 0.0000, Loss G: 21.4437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [99/100]: 100%|██████████| 576/576 [01:55<00:00,  4.98it/s, lossD=4.76e-10, lossG=21.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100] Loss D: 0.0000, Loss G: 21.7716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [100/100]: 100%|██████████| 576/576 [01:52<00:00,  5.10it/s, lossD=3.81e-10, lossG=21.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100] Loss D: 0.0000, Loss G: 21.3399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "epochs = 100\n",
    "fixed_noise = torch.randn(64, z_dim, 1, 1).to(device)\n",
    "\n",
    "# Store previous losses\n",
    "prev_lossG = float('inf')\n",
    "bad_gen_epochs = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(dataloader, desc=f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "    for batch in loop:\n",
    "        real = batch.to(device)\n",
    "        noise = torch.randn(real.size(0), z_dim, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "\n",
    "        ### Train Discriminator ###\n",
    "        disc_real = disc(real).view(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "\n",
    "        disc_fake = disc(fake.detach()).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### Train Generator ###\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # Feedback loop: train generator again if struggling\n",
    "        if lossG.item() > lossD.item():\n",
    "            gen.zero_grad()\n",
    "            noise2 = torch.randn(real.size(0), z_dim, 1, 1).to(device)\n",
    "            fake2 = gen(noise2)\n",
    "            output2 = disc(fake2).view(-1)\n",
    "            lossG2 = criterion(output2, torch.ones_like(output2))\n",
    "            lossG2.backward()\n",
    "            opt_gen.step()\n",
    "            lossG = (lossG + lossG2) / 2  # average loss after 2 rounds\n",
    "\n",
    "        loop.set_postfix(lossD=lossD.item(), lossG=lossG.item())\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] Loss D: {lossD:.4f}, Loss G: {lossG:.4f}\")\n",
    "\n",
    "    # Track consecutive bad epochs for generator\n",
    "    if lossG.item() > prev_lossG:\n",
    "        bad_gen_epochs += 1\n",
    "    else:\n",
    "        bad_gen_epochs = 0\n",
    "\n",
    "    prev_lossG = lossG.item()\n",
    "\n",
    "    # Optional: Early intervention if gen performs poorly for many epochs\n",
    "    if bad_gen_epochs >= 5:\n",
    "        print(\"Warning: Generator struggling for 5+ epochs. Consider lowering LR or adjusting model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e91e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# -------------------------\n",
    "# 1. Hyperparameters\n",
    "# -------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "z_dim = 100\n",
    "image_size = 64\n",
    "channels_img = 1  # for grayscale MURA images\n",
    "features_gen = 64\n",
    "features_disc = 64\n",
    "lr = 2e-6\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "# -------------------------\n",
    "# 2. Weight Initialization\n",
    "# -------------------------\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Generator\n",
    "# -------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, channels_img, features_g):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, features_g * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(features_g * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(features_g * 8, features_g * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_g * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(features_g * 4, features_g * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_g * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(features_g * 2, features_g, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_g),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(features_g, channels_img, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# -------------------------\n",
    "# 4. Discriminator\n",
    "# -------------------------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(channels_img, features_d, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(features_d, features_d * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_d * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(features_d * 2, features_d * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_d * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(features_d * 4, features_d * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(features_d * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(features_d * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# -------------------------\n",
    "# 5. Initialize Models\n",
    "# -------------------------\n",
    "gen = Generator(z_dim, channels_img, features_gen).to(device)\n",
    "disc = Discriminator(channels_img, features_disc).to(device)\n",
    "gen.apply(weights_init)\n",
    "disc.apply(weights_init)\n",
    "\n",
    "# -------------------------\n",
    "# 6. Optimizers and Loss\n",
    "# -------------------------\n",
    "criterion = nn.BCELoss()\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "# -------------------------\n",
    "# 7. Dataset & Loader (adjust root to your dataset)\n",
    "# -------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "class SafeImageFolder(ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        try:\n",
    "            sample = self.loader(path)\n",
    "        except (UnidentifiedImageError, OSError):\n",
    "            # Return a dummy image (black) and ignore this index\n",
    "            sample = Image.new('L', (image_size, image_size))  # Grayscale fallback\n",
    "            target = -1\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, target\n",
    "\n",
    "\n",
    "dataset = SafeImageFolder(root=\"C:/College/Projects/X-RayComparison/Data/train\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "fixed_noise = torch.randn(64, z_dim, 1, 1).to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e711eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/288 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 8. Training Loop\n",
    "# -------------------------\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "    for i, (real, _) in enumerate(loop):\n",
    "        real = real.to(device)\n",
    "        noise = torch.randn(real.size(0), z_dim, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "\n",
    "        ### Train Discriminator ###\n",
    "        disc_real = disc(real).view(-1)\n",
    "        label_real = torch.full_like(disc_real, 0.9)  # label smoothing\n",
    "        lossD_real = criterion(disc_real, label_real)\n",
    "\n",
    "        disc_fake = disc(fake.detach()).view(-1)\n",
    "        label_fake = torch.zeros_like(disc_fake)\n",
    "        lossD_fake = criterion(disc_fake, label_fake)\n",
    "\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### Train Generator ###\n",
    "        output = disc(fake).view(-1)\n",
    "        label_gen = torch.ones_like(output)  # try to fool D\n",
    "        lossG = criterion(output, label_gen)\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        loop.set_postfix(lossD=lossD.item(), lossG=lossG.item())\n",
    "\n",
    "    # Save samples\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "            fake_samples = gen(fixed_noise).detach().cpu()\n",
    "            grid = make_grid(fake_samples, normalize=True)\n",
    "            save_image(grid, f\"samples/fake_epoch_{epoch+1}.png\")\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] Loss D: {lossD.item():.4f}, Loss G: {lossG.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e928e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "z_dim = 100\n",
    "batch_size = 64\n",
    "lr = 2e-4\n",
    "image_size = 128\n",
    "channels_img = 1  # grayscale\n",
    "features_gen = 64\n",
    "features_disc = 64\n",
    "epochs = 100\n",
    "critic_iter = 1  # how often to train D per G update\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root='C:/College/Projects/X-RayComparison/Data/train', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, channels_img, features_g):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            self._block(z_dim, features_g * 16, 4, 1, 0),   # 1x1 -> 4x4\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # 4x4 -> 8x8\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),   # 8x8 -> 16x16\n",
    "            self._block(features_g * 4, features_g * 2, 4, 2, 1),   # 16x16 -> 32x32\n",
    "            self._block(features_g * 2, features_g, 4, 2, 1),       # 32x32 -> 64x64\n",
    "            nn.ConvTranspose2d(features_g, channels_img, 4, 2, 1),  # 64x64 -> 128x128\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def _block(self, in_c, out_c, k, s, p):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_c, out_c, k, s, p, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self._block(channels_img, features_d, 4, 2, 1),       # 128 -> 64\n",
    "            self._block(features_d, features_d * 2, 4, 2, 1),     # 64 -> 32\n",
    "            self._block(features_d * 2, features_d * 4, 4, 2, 1), # 32 -> 16\n",
    "            self._block(features_d * 4, features_d * 8, 4, 2, 1), # 16 -> 8\n",
    "            self._block(features_d * 8, features_d * 16, 4, 2, 1),# 8 -> 4\n",
    "            nn.Conv2d(features_d * 16, 1, 4, 1, 0),               # 4 -> 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _block(self, in_c, out_c, k, s, p):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, k, s, p, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x).view(-1)\n",
    "\n",
    "# Initialize\n",
    "gen = Generator(z_dim, channels_img, features_gen).to(device)\n",
    "disc = Discriminator(channels_img, features_disc).to(device)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()\n",
    "fixed_noise = torch.randn(64, z_dim, 1, 1).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]:   9%|▉         | 51/576 [00:25<04:21,  2.01it/s, lossD=0.178, lossG=8.3] \n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BufferedReader name='C:/College/Projects/X-RayComparison/Data/train\\\\XR_WRIST\\\\patient07840\\\\study2_negative\\\\._image3.png'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      3\u001b[0m     loop \u001b[38;5;241m=\u001b[39m tqdm(dataloader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (real, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loop):\n\u001b[0;32m      5\u001b[0m         real \u001b[38;5;241m=\u001b[39m real\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m         noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(real\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), z_dim, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torchvision\\datasets\\folder.py:245\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[1;32m--> 245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torchvision\\datasets\\folder.py:284\u001b[0m, in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torchvision\\datasets\\folder.py:263\u001b[0m, in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpil_loader\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Image\u001b[38;5;241m.\u001b[39mImage:\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 263\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\PIL\\Image.py:3532\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3530\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[0;32m   3531\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[1;32m-> 3532\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BufferedReader name='C:/College/Projects/X-RayComparison/Data/train\\\\XR_WRIST\\\\patient07840\\\\study2_negative\\\\._image3.png'>"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "    for i, (real, _) in enumerate(loop):\n",
    "        real = real.to(device)\n",
    "        noise = torch.randn(real.size(0), z_dim, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "\n",
    "        # Train Discriminator\n",
    "        disc_real = disc(real)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real) * 0.9)  # Label smoothing\n",
    "\n",
    "        disc_fake = disc(fake.detach())\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        # Train Generator\n",
    "        if i % critic_iter == 0:\n",
    "            output = disc(fake)\n",
    "            lossG = criterion(output, torch.ones_like(output))  # Generator wants D to output 1\n",
    "            gen.zero_grad()\n",
    "            lossG.backward()\n",
    "            opt_gen.step()\n",
    "\n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        loop.set_postfix(lossD=lossD.item(), lossG=lossG.item())\n",
    "\n",
    "    # Save samples\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        utils.save_image(gen(fixed_noise), f\"generated_epoch_{epoch+1}.png\", normalize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c36ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import grad\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_size = 128\n",
    "z_dim = 128\n",
    "batch_size = 64\n",
    "lambda_gp = 10\n",
    "num_epochs = 100\n",
    "lr = 1e-4\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "dataset_path = \"C:/College/Projects/X-RayComparison/Data/train\"  # Update this to the correct path\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=128, img_channels=1, features_g=64):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, features_g*16, 4, 1, 0),  # 4x4\n",
    "            nn.BatchNorm2d(features_g*16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g*16, features_g*8, 4, 2, 1),  # 8x8\n",
    "            nn.BatchNorm2d(features_g*8),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g*8, features_g*4, 4, 2, 1),  # 16x16\n",
    "            nn.BatchNorm2d(features_g*4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g*4, features_g*2, 4, 2, 1),  # 32x32\n",
    "            nn.BatchNorm2d(features_g*2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g*2, features_g, 4, 2, 1),  # 64x64\n",
    "            nn.BatchNorm2d(features_g),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(features_g, img_channels, 4, 2, 1),  # 128x128\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels=1, features_d=64):\n",
    "        super().__init__()\n",
    "        def block(in_c, out_c, k, s, p):\n",
    "            return nn.Sequential(\n",
    "                nn.utils.spectral_norm(nn.Conv2d(in_c, out_c, k, s, p)),\n",
    "                nn.LayerNorm([out_c, image_size // s, image_size // s]),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            )\n",
    "\n",
    "        self.disc = nn.Sequential(\n",
    "            block(img_channels, features_d, 4, 2, 1),    # 64\n",
    "            block(features_d, features_d*2, 4, 2, 1),     # 32\n",
    "            block(features_d*2, features_d*4, 4, 2, 1),   # 16\n",
    "            block(features_d*4, features_d*8, 4, 2, 1),   # 8\n",
    "            block(features_d*8, features_d*16, 4, 2, 1),  # 4\n",
    "            nn.Conv2d(features_d*16, 1, 4, 1, 0),         # 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x).view(-1)\n",
    "\n",
    "# Gradient Penalty\n",
    "def gradient_penalty(critic, real, fake):\n",
    "    batch_size, C, H, W = real.shape\n",
    "    epsilon = torch.rand(batch_size, 1, 1, 1, device=device).expand_as(real)\n",
    "    interpolated = (epsilon * real + (1 - epsilon) * fake).requires_grad_(True)\n",
    "\n",
    "    mixed_scores = critic(interpolated)\n",
    "    gradient = grad(\n",
    "        outputs=mixed_scores,\n",
    "        inputs=interpolated,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(batch_size, -1)\n",
    "    gp = ((gradient.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gp\n",
    "\n",
    "# Initialize\n",
    "gen = Generator(z_dim=z_dim).to(device)\n",
    "critic = Discriminator().to(device)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.0, 0.9))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=lr, betas=(0.0, 0.9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79c15a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_d=64):\n",
    "        super(Critic, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # Input: N x 1 x 128 x 128\n",
    "            nn.Conv2d(img_channels, feature_d, kernel_size=4, stride=2, padding=1),  # 64x64\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(feature_d, feature_d * 2, kernel_size=4, stride=2, padding=1),  # 32x32\n",
    "            nn.BatchNorm2d(feature_d * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(feature_d * 2, feature_d * 4, kernel_size=4, stride=2, padding=1),  # 16x16\n",
    "            nn.BatchNorm2d(feature_d * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(feature_d * 4, feature_d * 8, kernel_size=4, stride=2, padding=1),  # 8x8\n",
    "            nn.BatchNorm2d(feature_d * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(feature_d * 8, feature_d * 16, kernel_size=4, stride=2, padding=1),  # 4x4\n",
    "            nn.BatchNorm2d(feature_d * 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(feature_d * 16, 1, kernel_size=4, stride=1, padding=0),  # 1x1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1)\n",
    "\n",
    "# Example instantiation\n",
    "critic = Critic(img_channels=1).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964314a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "class SafeImageFolder(ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        try:\n",
    "            sample = self.loader(path)\n",
    "        except UnidentifiedImageError:\n",
    "            # Replace with a black image or skip with random image\n",
    "            sample = Image.new(\"L\", (128, 128))  # Grayscale fallback\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, target\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = SafeImageFolder(root=\"C:/College/Projects/X-RayComparison/Data/train\", transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae0c40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/576 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "critic_iterations = 5  # Number of updates for the discriminator per generator update\n",
    "step = 0\n",
    "fixed_noise = torch.randn(64, z_dim, 1, 1).to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "    for batch_idx, (real, _) in enumerate(loop):\n",
    "        real = real.to(device)\n",
    "        cur_batch_size = real.size(0)\n",
    "\n",
    "        ### Train Critic ###\n",
    "        for _ in range(critic_iterations):\n",
    "            noise = torch.randn(cur_batch_size, z_dim, 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "\n",
    "            critic_real = critic(real).reshape(-1)\n",
    "            critic_fake = critic(fake.detach()).reshape(-1)\n",
    "            gp = gradient_penalty(critic, real, fake)\n",
    "            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake)) + lambda_gp * gp\n",
    "\n",
    "            opt_critic.zero_grad()\n",
    "            loss_critic.backward()\n",
    "            opt_critic.step()\n",
    "\n",
    "        ### Train Generator ###\n",
    "        noise = torch.randn(cur_batch_size, z_dim, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "        output = critic(fake).reshape(-1)\n",
    "        loss_gen = -torch.mean(output)\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # Logging\n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        loop.set_postfix(critic_loss=loss_critic.item(), gen_loss=loss_gen.item())\n",
    "\n",
    "        # Save sample generated images\n",
    "        if step % 500 == 0:\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                utils.save_image(fake, f\"generated_samples/sample_{step}.png\", normalize=True)\n",
    "        step += 1\n",
    "\n",
    "    # Optional: Save model checkpoints every few epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(gen.state_dict(), f\"checkpoints/gen_epoch_{epoch+1}.pth\")\n",
    "        torch.save(critic.state_dict(), f\"checkpoints/critic_epoch_{epoch+1}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ea9d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training Loop\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fixed_noise \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m64\u001b[39m, z_dim, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (real, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(dataloader)):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "fixed_noise = torch.randn(64, z_dim, 1, 1).to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real, _) in enumerate(tqdm(dataloader)):\n",
    "        real = real.to(device)\n",
    "        cur_batch_size = real.size(0)\n",
    "\n",
    "        # Train Critic\n",
    "        for _ in range(5):\n",
    "            noise = torch.randn(cur_batch_size, z_dim, 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "\n",
    "            critic_real = critic(real)\n",
    "            critic_fake = critic(fake.detach())\n",
    "            gp = gradient_penalty(critic, real, fake)\n",
    "            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake)) + lambda_gp * gp\n",
    "\n",
    "            opt_critic.zero_grad()\n",
    "            loss_critic.backward()\n",
    "            opt_critic.step()\n",
    "\n",
    "        # Train Generator\n",
    "        noise = torch.randn(cur_batch_size, z_dim, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "        output = critic(fake)\n",
    "        loss_gen = -torch.mean(output)\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss D: {loss_critic:.4f} | Loss G: {loss_gen:.4f}\")\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        utils.save_image(fake[:64], f\"samples/wgan_gp_{epoch+1}.png\", normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and show last generated image\n",
    "from torchvision.io import read_image\n",
    "last_image = read_image(f\"{save_dir}/epoch_{epochs}.png\").float() / 255\n",
    "show_image(last_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c29c1e",
   "metadata": {},
   "source": [
    "Legacy Cells for reference (Not Working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5886f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m image\n\u001b[0;32m     23\u001b[0m dataset \u001b[38;5;241m=\u001b[39m XrayDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/College/Projects/X-RayComparison/Data/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m---> 24\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:376\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 376\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    378\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\utils\\data\\sampler.py:164\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "class XrayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.files = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith(\".png\")]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.files[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "dataset = XrayDataset(\"C:/College/Projects/X-RayComparison/Data/train\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823c676",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[14], line 11\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m transform \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mCompose([\n",
      "\u001b[0;32m      5\u001b[0m     T\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)),     \u001b[38;5;66;03m# You can use (128, 128) if GPU allows\u001b[39;00m\n",
      "\u001b[0;32m      6\u001b[0m     T\u001b[38;5;241m.\u001b[39mToTensor(),\n",
      "\u001b[0;32m      7\u001b[0m     T\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m,), (\u001b[38;5;241m0.5\u001b[39m,))\n",
      "\u001b[0;32m      8\u001b[0m ])\n",
      "\u001b[0;32m     10\u001b[0m dataset \u001b[38;5;241m=\u001b[39m MURAXrayDataset(IMG_DIR, transform\u001b[38;5;241m=\u001b[39mtransform)\n",
      "\u001b[1;32m---> 11\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:376\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n",
      "\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n",
      "\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n",
      "\u001b[1;32m--> 376\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    378\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\utils\\data\\sampler.py:164\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n",
      "\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n",
      "\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    161\u001b[0m     )\n",
      "\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[0;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    166\u001b[0m     )\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((64, 64)),     # You can use (128, 128) if GPU allows\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = MURAXrayDataset(IMG_DIR, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1581adb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([64])) that is different to the input size (torch.Size([1600])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[32], line 16\u001b[0m\n",
      "\u001b[0;32m     13\u001b[0m fake_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(batch_size, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;32m     15\u001b[0m output_real \u001b[38;5;241m=\u001b[39m discriminator(real_images)\n",
      "\u001b[1;32m---> 16\u001b[0m loss_real \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     18\u001b[0m output_fake \u001b[38;5;241m=\u001b[39m discriminator(fake_images\u001b[38;5;241m.\u001b[39mdetach())\n",
      "\u001b[0;32m     19\u001b[0m loss_fake \u001b[38;5;241m=\u001b[39m criterion(output_fake, fake_labels)\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\modules\\loss.py:697\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n",
      "\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "\u001b[1;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\n",
      "\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\nn\\functional.py:3545\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n",
      "\u001b[0;32m   3543\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n",
      "\u001b[0;32m   3544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n",
      "\u001b[1;32m-> 3545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[0;32m   3546\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   3547\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   3548\u001b[0m     )\n",
      "\u001b[0;32m   3550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m   3551\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([1600])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, real_images in enumerate(dataloader):\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        # Discriminator\n",
    "        noise = torch.randn(batch_size, latent_dim, 1, 1, device=device)\n",
    "        fake_images = generator(noise)\n",
    "\n",
    "        real_labels = torch.ones(batch_size, device=device)\n",
    "        fake_labels = torch.zeros(batch_size, device=device)\n",
    "\n",
    "        output_real = discriminator(real_images)\n",
    "        loss_real = criterion(output_real, real_labels)\n",
    "\n",
    "        output_fake = discriminator(fake_images.detach())\n",
    "        loss_fake = criterion(output_fake, fake_labels)\n",
    "\n",
    "        loss_D = loss_real + loss_fake\n",
    "        optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Generator\n",
    "        output = discriminator(fake_images)\n",
    "        loss_G = criterion(output, real_labels)\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}] Batch {i}/{len(dataloader)} | Loss D: {loss_D:.4f}, Loss G: {loss_G:.4f}\")\n",
    "\n",
    "    # Save generated images after each epoch\n",
    "    with torch.no_grad():\n",
    "        fake = generator(fixed_noise).detach().cpu()\n",
    "    grid = make_grid(fake, padding=2, normalize=True)\n",
    "    save_image(grid, f\"{save_dir}/epoch_{epoch+1}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc00f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [02:50<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] Loss D: 0.0002, Loss G: 9.2120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [02:03<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100] Loss D: 0.0004, Loss G: 10.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:26<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100] Loss D: 0.0128, Loss G: 14.6480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:14<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100] Loss D: 0.0014, Loss G: 8.9052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:14<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100] Loss D: 0.0001, Loss G: 9.5896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:13<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100] Loss D: 0.0001, Loss G: 9.9749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100] Loss D: 0.0000, Loss G: 10.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [02:18<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100] Loss D: 0.0000, Loss G: 10.9979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [02:08<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100] Loss D: 0.0000, Loss G: 11.2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [02:07<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100] Loss D: 0.0000, Loss G: 12.2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:52<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100] Loss D: 0.0000, Loss G: 13.2978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:22<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100] Loss D: 0.0000, Loss G: 13.5154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:26<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100] Loss D: 0.0000, Loss G: 13.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:22<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100] Loss D: 0.0000, Loss G: 13.9387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:22<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100] Loss D: 0.0001, Loss G: 11.6581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100] Loss D: 0.0000, Loss G: 14.5093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:15<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100] Loss D: 0.0000, Loss G: 13.8571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:15<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100] Loss D: 0.0000, Loss G: 13.6022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100] Loss D: 0.0000, Loss G: 14.8209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:12<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100] Loss D: 0.0000, Loss G: 15.0240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:13<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100] Loss D: 0.0000, Loss G: 15.3084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:15<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100] Loss D: 0.0000, Loss G: 16.4268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100] Loss D: 0.0000, Loss G: 16.5610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100] Loss D: 0.0000, Loss G: 16.9802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100] Loss D: 0.0000, Loss G: 17.1795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100] Loss D: 0.0000, Loss G: 17.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:18<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100] Loss D: 0.0000, Loss G: 17.5253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100] Loss D: 0.0001, Loss G: 9.4443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100] Loss D: 0.0000, Loss G: 11.2898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100] Loss D: 0.0000, Loss G: 10.9255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100] Loss D: 0.0000, Loss G: 11.4363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100] Loss D: 0.0000, Loss G: 12.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100] Loss D: 0.0000, Loss G: 15.5819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100] Loss D: 0.0000, Loss G: 12.4172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:17<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100] Loss D: 0.0000, Loss G: 14.2420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:17<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100] Loss D: 0.0000, Loss G: 13.8323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:16<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100] Loss D: 0.0000, Loss G: 14.5025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:18<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100] Loss D: 0.0000, Loss G: 14.8813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:20<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100] Loss D: 0.0000, Loss G: 15.7242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:15<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100] Loss D: 0.0000, Loss G: 16.3455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [01:15<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100] Loss D: 0.0000, Loss G: 15.6286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 427/576 [01:07<00:23,  6.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[36], line 7\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m fixed_noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m64\u001b[39m, z_dim, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n",
      "\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n",
      "\u001b[0;32m      8\u001b[0m         real \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;32m      9\u001b[0m         noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(real\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), z_dim, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n",
      "\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n",
      "\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n",
      "\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n",
      "\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n",
      "\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n",
      "\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n",
      "\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n",
      "\u001b[0;32m    707\u001b[0m ):\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n",
      "\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n",
      "\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n",
      "\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n",
      "\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n",
      "\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n",
      "\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\n",
      "Cell \u001b[1;32mIn[21], line 20\u001b[0m, in \u001b[0;36mMURAXrayDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n",
      "\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n",
      "\u001b[0;32m     19\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_paths[idx]\n",
      "\u001b[1;32m---> 20\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Convert to grayscale\u001b[39;00m\n",
      "\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "\u001b[0;32m     22\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\PIL\\Image.py:3465\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n",
      "\u001b[0;32m   3462\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fp)\n",
      "\u001b[0;32m   3464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n",
      "\u001b[1;32m-> 3465\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   3466\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;32m   3467\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 100\n",
    "fixed_noise = torch.randn(64, z_dim, 1, 1).to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in tqdm(dataloader):\n",
    "        real = batch.to(device)\n",
    "        noise = torch.randn(real.size(0), z_dim, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "\n",
    "        ### Train Discriminator ###\n",
    "        disc_real = disc(real).view(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "\n",
    "        disc_fake = disc(fake.detach()).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### Train Generator ###\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))  # Trick D into thinking fake is real\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] Loss D: {lossD:.4f}, Loss G: {lossG:.4f}\")\n",
    "\n",
    "    # Optional: save sample images here using torchvision.utils.save_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c6500",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[Errno 2] No such file or directory: './generated/epoch_100.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[39], line 12\u001b[0m\n",
      "\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load and show last generated image\u001b[39;00m\n",
      "\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m read_image\n",
      "\u001b[1;32m---> 12\u001b[0m last_image \u001b[38;5;241m=\u001b[39m \u001b[43mread_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msave_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/epoch_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;32m     13\u001b[0m show_image(last_image)\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torchvision\\io\\image.py:330\u001b[0m, in \u001b[0;36mread_image\u001b[1;34m(path, mode, apply_exif_orientation)\u001b[0m\n",
      "\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n",
      "\u001b[0;32m    329\u001b[0m     _log_api_usage_once(read_image)\n",
      "\u001b[1;32m--> 330\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decode_image(data, mode, apply_exif_orientation\u001b[38;5;241m=\u001b[39mapply_exif_orientation)\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torchvision\\io\\image.py:64\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n",
      "\u001b[0;32m     63\u001b[0m     _log_api_usage_once(read_file)\n",
      "\u001b[1;32m---> 64\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\n",
      "File \u001b[1;32mc:\\Apps\\Work\\Conda\\envs\\gan-xray\\lib\\site-packages\\torch\\_ops.py:1116\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n",
      "\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n",
      "\u001b[1;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [Errno 2] No such file or directory: './generated/epoch_100.png'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_image(tensor_img):\n",
    "    img = tensor_img.permute(1, 2, 0).squeeze().numpy()\n",
    "    plt.imshow((img + 1) / 2, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Load and show last generated image\n",
    "from torchvision.io import read_image\n",
    "last_image = read_image(f\"{save_dir}/epoch_{epochs}.png\").float() / 255\n",
    "show_image(last_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan-xray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
